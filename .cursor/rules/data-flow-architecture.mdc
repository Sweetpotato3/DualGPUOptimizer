---
<<<<<<< HEAD
<<<<<<< HEAD
description: Documents data flow between components for GPU resource management and optimization systems
globs: **/dualgpuopt/**/*.py,**/services/**/*.py,**/metrics/**/*.py
=======
description: Specifications for data flow between GPU optimization components, GPU monitoring, and performance metrics
globs: **/services/**,**/gpu_info.py,**/metrics.py,**/telemetry.py,**/event_*.py
>>>>>>> 199829b (Update documentation for DualGPUOptimizer to provide a high-level overview of GPU optimization and model inference systems. Organized content into key components: Core GPU Management, Model Optimization Engine, Command System, Monitoring Dashboard, and State Management. Enhanced glob patterns for improved file matching and clarified key implementation files, ensuring comprehensive coverage of system functionalities and integration points.)
=======
description: Documents data flows between system components including GPU telemetry, optimization parameters, and monitoring metrics
globs: 'dual_gpu_optimizer/dualgpuopt/*.py'
>>>>>>> 0727adb (Update documentation for Dual GPU Optimizer, enhancing descriptions of core components and workflows related to machine learning workload distribution and GPU resource management. Refined glob patterns for improved file matching and organized content for better readability, ensuring clarity on system functionalities and integration points.)
alwaysApply: false
---


# data-flow-architecture

<<<<<<< HEAD
<<<<<<< HEAD
Primary Data Flow Components:

1. GPU Telemetry Pipeline (telemetry.py -> event_bus.py)
- GPU metrics collection: utilization, memory, temperature, power, clocks
- Metrics transformed into domain events through EventBusMiddleware
- Real-time distribution to optimization and monitoring components
- Importance: 95

2. Optimization Data Flow (optimizer.py -> layer_balance.py)
- Memory split ratios calculated from GPU capabilities
- Layer distribution mapping based on latency profiles
- Command generation for framework-specific deployments
- Importance: 90

3. Resource Monitoring Flow (gpu_info.py -> metrics.py)
- Continuous GPU state tracking with 60-second history
- Multi-level update intervals:
  * Critical metrics: 500ms
  * Standard metrics: 1000ms 
  * Background metrics: 2000ms
- Importance: 85

4. Configuration Pipeline (config_service.py -> mpolicy.py)
- GPU-specific settings persistence
- Mixed precision policy distribution
- Overclocking profile management
- Importance: 80

5. Command Generation Flow (commands/gpu_commands.py -> optimizer.py)
- Framework-specific command construction
- GPU split ratio application
- Tensor parallelism configuration
- Importance: 75

Key Integration Points:
- Telemetry -> Optimizer: GPU capability data
- Optimizer -> Commands: Framework configurations
- Metrics -> Dashboard: Visualization data
- Config -> GPU Services: Hardware settings

Core Data Models:
```
GPUMetrics {
  utilization: float
  memory_used: int
  temperature: int
  power_draw: float
  clock_speeds: {core: int, memory: int}
}

OptimizationConfig {
  memory_splits: float[]
  layer_distribution: int[]
  tensor_parallel: int
}
```
=======
### Core Data Flows

1. GPU Resource Data Flow
- GPU metrics flow from telemetry collector through middleware pipeline to event bus
- Event bus distributes GPU metrics to dashboard, optimizer, and monitoring components 
- Real-time updates of utilization, memory, temperature delivered every 3 seconds
- GPU state changes trigger reoptimization of memory splits and tensor fractions

2. Optimization Parameter Flow  
- Model configuration flows from launcher UI to optimizer service
- Optimizer calculates GPU splits and generates framework-specific commands
- Results flow back through event bus to UI components
- Configuration changes trigger recalculation of optimization parameters

3. Monitoring Metrics Flow
- Prometheus metrics collector gathers batch latency and queue depth
- Metrics flow through optional middleware to monitoring endpoints
- GPU utilization history maintained for dashboard visualizations
- Idle detection triggers system tray notifications after 5 minutes

### Key Integration Points

1. Event Bus Hub
- Central event bus coordinates data flow between all components
- Priority-based dispatch ensures critical updates processed first
- Typed events provide structured data exchange
- Support for both sync and async event handling

2. State Management 
- Centralized state service maintains application configuration
- State changes broadcast via event bus to dependent components
- Persistent storage of GPU configurations and optimization settings
- Mock GPU mode toggles simulated data flow for testing

3. Error Handling Flow
- Errors flow through error service to logging and UI components
- GPU errors trigger mock mode activation if needed
- Critical errors force application restart
- Warning notifications delivered through system tray

4. Telemetry Pipeline
- Raw GPU metrics collected via NVML interface
- Middleware processes and enriches telemetry data
- Event bus publishes metrics to subscribers
- Dashboard maintains rolling 60-sample history

### File Paths
- `/services/event_bus.py`: Core event distribution
- `/services/state_service.py`: State management
- `/telemetry.py`: GPU metrics collection
- `/gpu_info.py`: GPU resource monitoring
- `/metrics.py`: Performance metrics
>>>>>>> 199829b (Update documentation for DualGPUOptimizer to provide a high-level overview of GPU optimization and model inference systems. Organized content into key components: Core GPU Management, Model Optimization Engine, Command System, Monitoring Dashboard, and State Management. Enhanced glob patterns for improved file matching and clarified key implementation files, ensuring comprehensive coverage of system functionalities and integration points.)
=======
### Primary Data Flows

1. GPU Telemetry Collection Flow (Importance: 95)
- `gpu_info.py` collects raw GPU data via NVML
- Data streams to `telemetry.py` for real-time polling and metrics aggregation
- Metrics flow to `optimizer.py` for workload distribution calculations
- Flow includes: utilization, memory, PCIe throughput, temperature, power, clocks

2. Optimization Parameter Flow (Importance: 90)
- `optimizer.py` receives GPU capabilities from `gpu_info.py`
- Calculates tensor fractions and memory splits
- Generates environment configurations 
- Outputs command-line arguments for ML frameworks
- Parameters flow to execution environment via env files

3. Monitoring Metrics Flow (Importance: 85)
- `telemetry.py` streams metrics via queue system
- `tray.py` receives utilization data for idle detection
- Notification triggers based on 30% utilization threshold
- Metrics logged for historical analysis

4. Configuration Data Flow (Importance: 80)
- `configio.py` manages configuration parameter distribution
- Settings flow to optimization components
- Parameters include GPU splits, tensor parallel sizes
- Configuration validated against GPU capabilities

### Key Integration Points

1. GPU Data Collection Interface (Importance: 85)
- `gpu_info.py` -> `telemetry.py`
- Real GPU or mock data generation
- Structured GPU objects with standardized metrics

2. Optimization Parameter Distribution (Importance: 80)
- `optimizer.py` -> Framework command generation
- Memory split calculations
- Tensor fraction distribution
- Environment variable generation

3. Monitoring Interface (Importance: 75)
- `telemetry.py` -> `tray.py`
- Queue-based metric streaming
- Threshold-based notifications
- System tray integration
>>>>>>> 0727adb (Update documentation for Dual GPU Optimizer, enhancing descriptions of core components and workflows related to machine learning workload distribution and GPU resource management. Refined glob patterns for improved file matching and organized content for better readability, ensuring clarity on system functionalities and integration points.)

$END$