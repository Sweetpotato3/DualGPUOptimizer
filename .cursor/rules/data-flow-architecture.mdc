---
description: Documents data flow patterns for GPU optimization and model execution across system components
globs: *.py,**/dualgpuopt/**/*.py
alwaysApply: false
---


# data-flow-architecture

The data flow architecture implements specialized flows for GPU resource optimization and model execution:

## Core Data Flow Components

1. GPU Telemetry Pipeline
- Source: `dualgpuopt/telemetry.py`
- Collects real-time GPU metrics including:
  * Memory utilization
  * Power consumption 
  * Temperature
  * Fan speeds
  * Clock rates
- Publishes through event bus to monitoring components
- Maintains 60-sample rolling window for trend analysis

2. Model Parameter Flow
- Source: `dualgpuopt/gui/launcher/parameter_resolver.py`
- Routes model configuration data:
  * Context size calculations
  * GPU memory split ratios
  * Layer distribution mappings
  * Tensor parallelism settings
- Validates parameters against hardware constraints
- Generates framework-specific launch configurations

3. Memory Management Pipeline 
- Source: `dualgpuopt/memory/monitor.py`
- Tracks GPU memory allocation patterns
- Maintains usage thresholds and alerts
- Coordinates memory reclamation during OOM events
- Routes memory metrics to optimization components

4. Optimization Event Flow
- Source: `dualgpuopt/services/event_bus.py`
- Handles bi-directional flow of:
  * GPU configuration changes
  * Performance metrics
  * Resource allocation decisions
  * Alert conditions
- Prioritizes critical GPU operations

## Key Integration Points

1. Model Launch Flow
- Source: `dualgpuopt/gui/launcher/launch_controller.py`
- Coordinates data flow between:
  * Parameter validation
  * Resource allocation
  * Model initialization
  * Performance monitoring

2. Batch Processing Pipeline
- Source: `dualgpuopt/batch/smart_batch.py`
- Manages flow of:
  * Sequence length metrics
  * Batch size calculations
  * Memory usage projections
  * Performance feedback

3. Layer Distribution Flow
- Source: `dualgpuopt/layer_balance.py`
- Routes layer assignments between GPUs based on:
  * Performance profiling data
  * Memory availability
  * Hardware capabilities
  * Model architecture

Importance Scores:
- GPU Telemetry Pipeline: 95 - Critical for optimization decisions
- Model Parameter Flow: 90 - Core model execution configuration
- Memory Management: 85 - Essential resource coordination
- Optimization Events: 80 - Key system coordination
- Launch Flow: 75 - Model execution orchestration
- Batch Processing: 70 - Performance optimization
- Layer Distribution: 70 - Resource utilization

$END$