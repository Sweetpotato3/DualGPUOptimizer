---
description: Documents data flow patterns and integration points between GPU resource management, optimization parameters, and monitoring metrics.
globs: 
alwaysApply: false
---


# data-flow-architecture

## Core Data Flow Patterns

### GPU Resource Data Flow
1. Memory Profiler -> Event Bus -> Optimization Engine:
- Memory profiler collects real-time GPU memory metrics
- Aggregated metrics flow through event bus system
- Optimizer engine consumes metrics to adjust allocation strategies
- Key metrics: VRAM usage, tensor distribution ratios, temperature

2. GPU Command Generation Flow:
- Model parameters flow into command generators
- Command generators produce framework-specific launch configurations
- Launch configurations flow to process monitor
- Process monitor streams execution metrics back to telemetry system

### Optimization Parameter Flow
1. Model -> Split Calculator -> GPU Allocator:
- Model architecture parameters flow into split calculator
- Split calculator determines optimal tensor splits
- Split ratios flow to GPU allocator
- Allocator applies memory distribution across GPUs

2. Settings -> State Service -> Components:
- User settings flow through state service
- State changes trigger event notifications
- Components react to state updates
- Settings persistence through config service

### Monitoring Metrics Flow
1. Telemetry -> Event Bus -> Dashboard:
- GPU metrics collected by telemetry service
- Metrics flow through event bus to subscribers 
- Dashboard components visualize real-time data
- Alert system processes threshold violations

2. Memory Monitor -> Recovery System:
- Memory usage patterns flow to monitor
- Monitor detects potential issues
- Recovery system receives alert triggers
- Recovery actions flow back to GPU management

## Key Integration Points

### Event Bus Integration
- Centralized event distribution system
- Connects monitoring, optimization and UI layers
- Handles metric aggregation and distribution
- Manages state change notifications

### State Service Integration  
- Maintains application-wide state
- Distributes configuration changes
- Handles settings persistence
- Manages optimization parameters

### Telemetry Integration
- Collects GPU performance metrics
- Distributes metrics to monitoring components
- Handles alert threshold evaluation
- Provides historical metric storage

## Data Flow Files

Core Components:
```
dualgpuopt/memory/profiler.py
dualgpuopt/services/event_bus.py 
dualgpuopt/services/state_service.py
dualgpuopt/telemetry.py
dualgpuopt/optimizer.py
```

Integration Points:
```
dualgpuopt/gui/dashboard.py
dualgpuopt/commands/gpu_commands.py
dualgpuopt/memory/monitor.py
```

$END$