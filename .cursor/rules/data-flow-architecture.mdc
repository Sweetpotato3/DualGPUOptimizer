---
description: Defines data flow paths and exchange patterns between GPU optimization components and resource monitoring systems
globs: **/dualgpuopt/**/*.py,**/*gpu*.py,**/services/*.py
alwaysApply: false
---


# data-flow-architecture

Data Flow Architecture: GPU Resource Optimization System

Primary Data Flows:

1. GPU Resource Telemetry Pipeline (Importance: 95)
```
GPU Hardware -> Telemetry Service -> Event Bus -> Dashboard/Optimizer
```
- Continuous polling of GPU metrics (utilization, temperature, power, memory)
- Middleware-based metric normalization and aggregation
- Event-driven updates to visualization and optimization components
- File: dualgpuopt/telemetry.py

2. Model Parameter Distribution (Importance: 90)
```
Optimizer -> Layer Balancer -> Command Generator -> Runner
```
- Model architecture parameters (layers, heads, dimensions)
- Memory allocation calculations per GPU
- Tensor split configurations
- Framework-specific command generation
- Files: dualgpuopt/optimizer.py, dualgpuopt/layer_balance.py

3. GPU State Management Pipeline (Importance: 85)
```
State Service -> Event Bus -> Services -> UI Components
```
- GPU configuration state (overclock, fans, power limits)
- Model execution context parameters
- Idle detection thresholds
- Resource allocation state
- File: dualgpuopt/services/state_service.py

4. Smart Batching Data Flow (Importance: 80)
```
Model Input -> Length Analyzer -> Batch Optimizer -> GPU Executor
```
- Sequence length-based grouping
- Memory-aware batch size calculations
- GPU-specific workload distribution
- File: dualgpuopt/batch/smart_batch.py

Key Integration Points:

1. GPU Hardware Interface Layer (Importance: 95)
- Direct hardware metric collection
- NVML integration for GPU control
- Memory management operations
- File: dualgpuopt/gpu_info.py

2. Framework Integration Layer (Importance: 85)
- llama.cpp parameter routing
- vLLM tensor configuration flow
- Model-specific optimization paths
- Files: dualgpuopt/gui/launcher.py, dualgpuopt/commands/gpu_commands.py

Core Data Exchange Patterns:
- Event-driven GPU metric updates (100ms minimum interval)
- Batch-oriented model parameter processing
- State-based configuration management
- Real-time monitoring data streams

$END$