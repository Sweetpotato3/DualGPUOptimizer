---
description: Specification for analyzing and documenting data flow patterns between components in GPU optimization systems
globs: 
alwaysApply: false
---


# data-flow-architecture

Key Data Flow Components:

1. GPU Telemetry Pipeline
- Telemetry service collects GPU metrics (utilization, memory, temperature)
- EventBusMiddleware publishes metrics to application event bus
- LoggingMiddleware handles diagnostic data streams
- Components subscribe to metrics via event bus for real-time updates
- Mock data generation provides fallback data flow when hardware unavailable

2. Model Optimization Data Flow
- Optimizer calculates memory splits and tensor parallel configurations
- Layer balancing algorithm receives performance profiles:
  - Short sequence (64 tokens) profile weighted at 20%
  - Long sequence (1024 tokens) profile weighted at 80%
- Distributes model layers across GPUs based on performance ratios
- Sends configuration commands to ML frameworks (llama.cpp, vLLM)

3. Memory Management Pipeline
- MemoryMonitor tracks per-model memory profiles:
  - Base memory footprint
  - Per-batch memory scaling 
  - Token memory requirements
  - Growth characteristics
- OOM prevention system implements recovery stages:
  1. Cache clearing
  2. Batch size reduction 
  3. Memory offloading
  4. Process termination

4. Configuration Data Flow
- StateService manages centralized application state
- Persistent storage maintains GPU settings and model configurations
- Event bus publishes state changes to subscribers
- Components receive updates through state change subscriptions

5. Command Generation Pipeline  
- Optimizer generates framework-specific commands
- Parameters flow from:
  - GPU memory calculations
  - Layer distribution profiles
  - Model architecture settings
  - Runtime configurations
- Commands distributed to framework runners

Relevant Files:
- dualgpuopt/telemetry.py
- dualgpuopt/memory_monitor.py
- dualgpuopt/services/state_service.py
- dualgpuopt/optimizer.py
- dualgpuopt/layer_balance.py

$END$