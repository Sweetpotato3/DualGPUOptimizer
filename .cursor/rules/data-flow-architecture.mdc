---
description: Data flow architecture documentation for dual-GPU optimization system with telemetry, memory monitoring, and model execution coordination.
globs: **/dualgpuopt/**/*.py,**/dual_gpu_optimizer/**/*.py,**/integrated_app/**/*.py
alwaysApply: false
---


# data-flow-architecture

## Telemetry Data Flow
- GPU metrics collection (`dualgpuopt/telemetry.py`) publishes utilization, memory, temperature and power metrics through event bus
- Metrics aggregation and windowing system maintains 60-second historical buffer
- Real-time metric streaming flows to dashboard visualizations and monitoring components
- Failure recovery with exponential backoff and mock data fallback

## Memory Management Flow 
- Memory profiler (`dualgpuopt/memory/profiler.py`) tracks inference memory patterns
- Memory anomaly detection (leaks, spikes) triggers alerts through event bus
- Historical memory patterns flow to memory timeline visualization
- Leak detection results feed into optimization recommendations

## Model Launch Workflow
- Framework-specific command generation based on model/GPU configuration
- GPU memory split calculation distributes model across available GPUs
- Dynamic tensor parallelism optimization based on available VRAM
- Process monitoring with stdout/stderr streaming to UI

## Core Data Flow Components

### Event Bus System
- Centralized event bus (`dualgpuopt/services/event_bus.py`) coordinates data flow between components
- Type-safe event subscription model
- Priority-based event handling
- Event replay capability for late subscribers

### Metrics Storage
- Rolling time-series buffer with 60s retention
- Thread-safe sample collection
- Automatic pruning of expired metrics
- Snapshot capability for point-in-time analysis

### Alert Flow
- Multi-level alert system (Emergency, Critical, Warning) 
- Temperature and memory thresholds trigger alerts
- Alert aggregation prevents notification flooding
- Alert history maintained for analysis

## Data Flow Paths

1. GPU Telemetry Path:
```
NVML Collection -> Event Bus -> Dashboard/Charts
                            -> Alert System  
                            -> Metrics Storage
```

2. Memory Monitoring Path:
```
Memory Profiler -> Event Bus -> Timeline View
                            -> Alert System
                            -> Optimization Engine
```

3. Model Execution Path: 
```
Launch Config -> Command Gen -> Process Monitor -> Log Stream
                                              -> Status Updates
```

All data flows are coordinated through the central event bus, enabling loose coupling between components while maintaining a consistent flow of telemetry, alerts and status updates throughout the system.

$END$