---
description: Documents data flow between components for GPU resource management, optimization parameters, and monitoring metrics
globs: *.py,dualgpuopt/**/*.py
alwaysApply: false
---


# data-flow-architecture

The dual GPU optimizer implements a multi-layered data flow architecture focused on GPU resource optimization:

## Core Data Flows

1. GPU Telemetry Pipeline
- Source: GPU hardware via NVML API 
- Metrics flow: Hardware → Telemetry Service → Event Bus → Dashboard
- Key metrics:
  * Memory utilization
  * Temperature
  * Power consumption
  * Clock speeds
  * PCIe bandwidth

2. Memory Profile Data Flow
- Memory session data captures:
  * Allocation/deallocation events
  * Growth spikes
  * Leak patterns
  * Inference boundaries
- Flow: Profiler → Memory Timeline → Analysis Engine → Dashboard

3. Optimization Parameter Flow
- Model configuration data:
  * Context sizes
  * Layer distributions
  * Split ratios
  * Memory constraints
- Flow: Optimizer → Command Generator → Process Runner

4. Event Distribution System
- Centralized event bus for metric propagation
- Priority-based event handling (LOW to CRITICAL)
- Specialized GPU event types for resource monitoring

## Key Integration Points

1. Memory Monitoring Chain
File: dualgpuopt/memory/profiler.py
- Memory event capture → Session tracking → Pattern analysis → Visualization
- Leak detection via regression analysis
- Event categorization and severity assignment

2. Resource Optimization Flow
File: dualgpuopt/optimizer.py
- Model parameters → Memory calculations → Split optimization → Command generation
- Tensor parallel configuration
- Layer distribution algorithms

3. Command Generation Pipeline
File: dualgpuopt/commands/gpu_commands.py
- Framework-specific parameter optimization
- Resource allocation validation
- Command string generation with GPU splits

4. Telemetry Distribution
File: dualgpuopt/telemetry.py
- Raw metrics → Processing pipeline → Event distribution → UI updates
- Middleware-based metric processing
- Real-time monitoring streams

The architecture emphasizes real-time metric flow and optimization parameter distribution across multiple GPU resources while maintaining consistent state through the event bus system.

$END$