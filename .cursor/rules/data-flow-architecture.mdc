---
description: Defines data flow patterns and architectures for GPU optimization systems and model inference pipelines
globs: **/dualgpuopt/**/*.py,**/dual_gpu_optimizer/**/*.py,**/integrated_app/**/*.py
alwaysApply: false
---


# data-flow-architecture

Core Data Flow Components:

1. GPU Telemetry Pipeline
- Collects real-time GPU metrics through NVML interface
- Routes performance data through EventBus to visualization components
- Maintains 60-sample rolling window of historical metrics
- Key flows: utilization %, memory usage, temperature, power draw
- File: dualgpuopt/telemetry.py

2. Model Deployment Pipeline
- Validates model paths and configurations
- Calculates optimal GPU splits based on VRAM availability
- Generates framework-specific launch commands
- Monitors execution state and resource allocation
- Files: dualgpuopt/optimizer.py, dualgpuopt/runner.py

3. Memory Management Flow
- Tracks per-GPU memory allocation and usage
- Implements OOM prevention through monitoring service
- Routes memory pressure alerts through event system
- Triggers cache clearing and recovery procedures
- Files: dualgpuopt/memory/monitor.py, dualgpuopt/memory/recovery.py

4. Event Bus Architecture
- Central event distribution system for GPU metrics
- Priority-based event routing (LOW -> CRITICAL)
- Specialized handlers for:
  * GPU metrics events
  * Memory alerts
  * Model execution status
- File: dualgpuopt/services/event_bus.py

5. Configuration Flow
- Loads model presets and GPU configurations
- Routes settings changes through state service
- Persists optimization parameters and hardware profiles
- Files: dualgpuopt/services/config_service.py

6. Layer Distribution Pipeline
- Calculates optimal layer splits across GPUs
- Routes tensor parallel configurations to model runners
- Manages model architecture requirements
- File: dualgpuopt/layer_balance.py

Integration Points:
- GPU metrics -> EventBus -> Dashboard visualization
- Model configuration -> Optimizer -> Command generation
- Memory alerts -> Recovery service -> Resource management
- Layer distribution -> Model runner -> Execution monitoring

$END$