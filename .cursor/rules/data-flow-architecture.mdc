---
description: Guidelines for analyzing data flow between GPU optimization components, resource monitoring, and model deployment services
globs: **/*.py,**/gpu_*.py,**/optimizer/*.py,**/services/*.py
alwaysApply: false
---


# data-flow-architecture

Primary Data Flow Paths:

1. GPU Telemetry Pipeline
- Collection Layer:
  - GPU metrics gathered via NVML interface (dualgpuopt/telemetry.py)
  - Real-time metrics: utilization, memory, temperature, power, clocks
- Processing Layer:
  - EventBusMiddleware transforms raw metrics into structured events
  - LoggingMiddleware handles debug telemetry
- Distribution Layer:
  - Event bus propagates metrics to dashboard and optimizer components
  - Priority-based event routing (LOW to CRITICAL)

2. Model Deployment Flow
- Parameters Flow:
  - Context size calculator determines safe window sizes (ctx_size.py)
  - Layer balancer distributes model across GPUs (layer_balance.py)
  - Memory policy handler sets precision rules (mpolicy.py)
- Command Generation:
  - Optimizer generates framework-specific commands
  - Environment variables configured for tensor parallelism
  - Resource limits applied based on GPU capabilities

3. Resource Management Pipeline
- Memory Management:
  - VRAM monitoring with 256MB warning threshold
  - Reclamation system tracks memory deltas
  - Automatic cleanup triggers at thresholds
- GPU Load Distribution:
  - Layer quotas calculated from performance ratios
  - Tensor parallel splits based on memory capacity
  - Workload routing through performance-optimized paths

4. Configuration Flow
- Settings Distribution:
  - GPU profiles propagate through config service
  - Overclocking parameters validated against safety limits
  - Idle detection thresholds synchronized across components
- State Management:
  - GPU state changes trigger event cascades
  - Profile changes propagate through event bus
  - Command history maintained for operation rollback

Key Integration Points:
- dualgpuopt/telemetry.py: Metrics collection and distribution
- dualgpuopt/optimizer.py: Resource allocation and command generation
- dualgpuopt/services/event_bus.py: Event routing and state propagation
- dualgpuopt/layer_balance.py: Workload distribution logic

The architecture emphasizes real-time metric flow, safe resource distribution, and coordinated state management across dual GPU configurations.

$END$