---
description: Specification for documenting data flows between components for GPU resource management and optimization systems
globs: dual_gpu_optimizer/**,integrated_app/**
alwaysApply: false
---


# data-flow-architecture

Core Data Flow Components:

1. GPU Metrics Pipeline
- GPUMetricsEvent streams real-time telemetry:
  * Utilization, memory, temperature, power data
  * PCIe bandwidth metrics
  * Clock speeds
- Collected by telemetry service (`dualgpuopt/telemetry.py`)
- Published through EventBus (`services/event_bus.py`)
- Consumed by Dashboard (`gui/dashboard.py`)

2. Optimization Parameter Flow
- Context size calculations (`ctx_size.py`) →
- Layer balance optimizer (`layer_balance.py`) →
- GPU command generator (`commands/gpu_commands.py`)
- Parameters include:
  * Memory split ratios
  * Tensor parallel fractions
  * Context length limits
  * Layer distribution maps

3. State Management Chain
- Configuration Service (`services/config_service.py`)
  * Stores GPU profiles
  * Manages overclock settings
  * Maintains idle thresholds
- State Service (`services/state_service.py`)
  * Tracks optimization state
  * Manages GPU context sizes
  * Handles model configurations
- Persisted to disk via ConfigIO (`configio.py`)

4. Error Handling Flow
- Error Service (`services/error_service.py`) detects GPU failures
- Publishes through EventBus to ErrorHandlers
- Triggers mock mode transitions
- Maintains error state history

5. Batch Processing Pipeline
- Smart batching system (`batch/smart_batch.py`)
- Sequences flow through:
  * Length-based bucketing
  * GPU memory optimization
  * Token-aware distribution
- Results feed back to monitoring system

Key Integration Points:
- `event_bus.py`: Central message broker
- `state_service.py`: State coordination
- `telemetry.py`: Metrics collection
- `optimizer.py`: Resource allocation

Data flows form a closed loop:
Metrics Collection → State Updates → Optimization → Command Generation → Execution → Metrics Collection

$END$