---
description: Specifies GPU memory optimization and tensor parallel distribution algorithms for maximizing dual-GPU utilization
globs: **/optimizer.py,**/gpu_info.py,**/gpu/*.py,**/memory/*.py,**/telemetry/*.py
alwaysApply: false
---


# gpu-optimization-algorithms

## Memory Distribution Core Components

1. **GPU Split Optimization**
- Located in `dualgpuopt/optimizer.py`
- Calculates optimal memory distribution across multiple GPUs based on:
  * Per-token memory requirements for KV cache 
  * Tensor parallelism overhead (20%)
  * System memory overhead (2GB default)
  * Safety margin (10% default)
  * KV cache factor adjustments (2.0x default)

2. **Memory Pattern Analysis**
- Located in `dualgpuopt/memory/profiler.py` 
- Real-time detection of memory usage patterns during LLM inference
- Identifies memory spikes, leaks and retention
- Tracks per-inference memory metrics:
  * Token counts
  * Memory deltas
  * GPU-specific allocation patterns
  * Growth rates and recovery patterns

3. **Tensor Split Calculation**
- Located in `dualgpuopt/optimizer.py`
- Determines optimal tensor parallel splits based on:
  * Available GPU memory ratios
  * Model layer counts
  * Attention head configuration
  * MoE model factors (if applicable)
  * Framework-specific constraints

4. **Memory Telemetry**
- Located in `dualgpuopt/telemetry.py`
- Implements specialized metrics collection for dual GPU systems
- Maintains 60-second rolling window of historical metrics
- Classifies alerts based on thresholds:
  * EMERGENCY: Memory ≥95%, Temperature ≥90°C
  * CRITICAL: Memory ≥90%, Temperature ≥80°C, Power ≥98%
  * WARNING: Memory ≥75%, Temperature ≥70°C, Power ≥90%

5. **VRAM Recovery System**
- Located in `dualgpuopt/vram_reset.py`
- Multi-strategy GPU memory reclamation:
  * CACHE_ONLY: PyTorch cache clearing
  * CLOCK_RESET: GPU clock management
  * FULL_RESET: Comprehensive memory cleanup
  * SYSTEM_CMD: OS-specific commands
- Implements platform-specific memory reclamation for Windows/Linux

## Importance Scores

- GPU Split Optimization: 95 (Core memory distribution logic)
- Memory Pattern Analysis: 90 (Critical for leak detection)
- Tensor Split Calculation: 85 (Key for model parallelization)
- Memory Telemetry: 80 (Essential monitoring system)
- VRAM Recovery: 75 (Important but supplementary)

$END$