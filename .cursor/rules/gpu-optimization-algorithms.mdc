---
description: Defines GPU memory management, tensor splitting, and optimization algorithms for dual GPU model execution
globs: **/optimizer.py,**/gpu_info.py,**/ctx_size.py,**/layer_balance.py
alwaysApply: false
---


# gpu-optimization-algorithms

### GPU Memory Distribution
`optimizer.py`:
- Calculates optimal memory splits between GPUs based on total VRAM
- Determines tensor parallel fractions for model layer distribution
- Generates environment configurations for CUDA/NCCL memory allocation
- Importance: 95

### Context Size Management
`ctx_size.py`:
- Computes maximum safe context length for models
- Adjusts context windows based on:
  - Available GPU memory
  - Model parameter count
  - Precision settings (FP16/BF16)
- Importance: 90

### Layer Balancing
`layer_balance.py`:
- Redistributes model layers across dual GPUs based on:
  - Layer execution latency
  - Memory requirements
  - Communication overhead
- Generates device mapping for optimal layer placement
- Importance: 85

### Memory Allocation Strategy 
`gpu_info.py`:
- Probes GPU memory allocation patterns
- Tracks memory fragmentation and usage
- Implements parallel GPU memory scanning
- Provides mock GPU data generation for testing
- Importance: 80

### Key Integration Points
- Memory distribution algorithms interface with NVML for real-time GPU metrics
- Layer balancing coordinates with model frameworks for tensor redistribution
- Context size calculations integrate with model loaders
- Memory allocation interfaces with CUDA memory management
- Importance: 75

$END$