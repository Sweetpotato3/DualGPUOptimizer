---
description: GPU optimization algorithms, memory distribution calculations, and tensor parallel splits for multi-GPU ML model inference
globs: **/gpu/**,**/optimizer.py,**/gpu_info.py,**/memory/**,**/metrics.py,**/telemetry.py
alwaysApply: false
---


# gpu-optimization-algorithms

Core GPU Memory Management Components:

1. Memory Distribution Calculator (optimizer.py)
- Calculates optimal memory splits between GPUs for LLM inference:
  - Base memory reservation (2GB per GPU)
  - Dynamic ratio based on available VRAM
  - Safety margin of 10% for system overhead
  - Tensor parallel overhead factor (20%)
- Generates framework-specific GPU distribution commands for:
  - llama.cpp: Percentage-based splits 
  - vLLM: Tensor parallel size configuration

2. Memory Predictor Engine (memory/predictor.py)
- Dynamic memory growth estimation per model:
  - Base memory footprint calculation
  - Per-token growth rate tracking
  - Batch size memory scaling
  - KV cache overhead estimation
- Model-specific profiling rules:
  - LLaMA models: 120 bytes per token
  - Mixtral: Additional 20% MoE overhead
  - Mistral: GQA-adjusted cache calculations

3. Layer Balancing System (layer_balance.py)
- Weighted performance distribution across GPUs:
  - 20% weight for short sequences (64 tokens)
  - 80% weight for long sequences (1024 tokens) 
- Layer block optimization:
  - Contiguous block formation
  - Small block merging (<3 layers)
  - Architecture-aware placement
  - Embedding/output layer positioning

4. Real-time Monitoring (telemetry.py)
- Critical GPU metrics collection:
  - Memory allocation tracking
  - Utilization percentages
  - Temperature monitoring
  - Power consumption analysis
  - PCIe bandwidth utilization
- OOM prevention through:
  - Proactive memory reclamation
  - Load distribution adjustment
  - Cache clearing triggers
  - Emergency process termination

Importance Scores:
- Memory Distribution Calculator: 95 (core optimization logic)
- Memory Predictor Engine: 90 (critical for preventing OOM)
- Layer Balancing System: 85 (key for multi-GPU performance)
- Real-time Monitoring: 75 (essential support system)

$END$