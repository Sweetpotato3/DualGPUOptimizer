---
description: GPU optimization algorithms documentation for memory distribution and tensor parallel splits.
globs: **/optimizer.py,**/gpu_info.py,**/telemetry.py
alwaysApply: false
---


# gpu-optimization-algorithms

## Core GPU Memory Distribution (Importance: 95)
`dual_gpu_optimizer/dualgpuopt/optimizer.py`

The GPU memory distribution system calculates optimal tensor splits across multiple GPUs:
- Determines memory allocation strategy based on available GPU capacities
- Computes tensor fractions for distributing model layers
- Generates split configurations for parallel processing
- Creates environment settings for GPU visibility and memory limits

## GPU Discovery and Telemetry (Importance: 85) 
`dual_gpu_optimizer/dualgpuopt/gpu_info.py`

The GPU detection system leverages NVML to:
- Discover available NVIDIA GPUs in parallel using concurrent processing
- Extract detailed GPU specifications including:
  - Memory capacity and availability
  - Device index and name
  - Current utilization state

## Real-time Monitoring (Importance: 75)
`dual_gpu_optimizer/dualgpuopt/telemetry.py`

Real-time GPU monitoring system that:
- Streams telemetry data using NVML interface
- Tracks GPU load patterns
- Monitors memory usage fluctuations
- Measures PCIe throughput

## Framework-Specific Optimizations (Importance: 90)
`dual_gpu_optimizer/dualgpuopt/optimizer.py`

Specialized optimization algorithms for LLM frameworks:
- Generates optimized command configurations for llama.cpp
- Creates vLLM-specific tensor parallel strategies
- Adjusts split ratios based on framework requirements
- Produces environment configurations tuned per framework

$END$