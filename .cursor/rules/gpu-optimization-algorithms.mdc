---
description: Technical documentation for GPU memory optimization algorithms, tensor splits and allocation strategies
globs: **/optimizer.py,**/gpu_info.py
alwaysApply: false
---


# gpu-optimization-algorithms

## Core GPU Memory Distribution (Importance: 95)
`optimizer.py` implements the critical GPU memory splitting logic:

- Calculates optimal tensor parallel splits across available GPUs based on relative memory capacities
- Generates normalized memory fractions for balanced workload distribution
- Produces environment configurations for NCCL and OMP settings to enable efficient multi-GPU operation

## GPU Resource Detection (Importance: 85)
`gpu_info.py` handles GPU resource discovery and management:

- Detects available NVIDIA GPUs using NVML interface 
- Retrieves real-time memory usage and device capabilities
- Provides mock GPU data capability for testing scenarios

## Memory Allocation Strategy (Importance: 90)
Memory allocation algorithms in `optimizer.py`:

- Split string generation algorithm maps total available GPU memory to allocation ratios
- Tensor fraction calculator normalizes memory distribution across asymmetric GPU configurations
- Command generation system produces optimized launch parameters for llama.cpp and vLLM based on calculated splits

## GPU Workload Optimization (Importance: 80)
Core optimization logic:

- Dynamically adjusts tensor parallel size based on detected GPU configurations
- Calculates optimal context sizes for model execution
- Generates environment settings for cross-GPU communication optimization

$END$