---
description: GPU memory distribution algorithms, tensor parallel splits calculation, and optimization from optimizer.py and gpu_info.py
globs: **/*.py
alwaysApply: false
---


# gpu-optimization-algorithms

## Core GPU Memory Distribution (Importance: 95)
Located in `dual_gpu_optimizer/dualgpuopt/optimizer.py`:

- Memory split calculation for multiple GPUs based on relative capacities
- Tensor fraction distribution across available GPUs
- Framework-specific configuration generation for memory splits
- Memory buffer reservations with 90% utilization target

## Layer Balance Management (Importance: 90) 
Located in `dual_gpu_optimizer/dualgpuopt/layer_balance.py`:

- Adaptive latency-aware layer distribution across GPUs
- Dual sequence length profiling (64/1024 tokens)
- Layer balancing with VRAM quota enforcement
- Weighted distribution based on execution profiles

## Context Size Calculations (Importance: 85)
Located in `dual_gpu_optimizer/dualgpuopt/ctx_size.py`:

- Maximum safe context length determination
- Model-specific parameter handling:
  - Layer count adjustments
  - KV head calculations
  - Head dimension scaling
  - MoE factor integration
- Reserved memory buffer management (2GB default)

## Smart Batching System (Importance: 80)
Located in `dual_gpu_optimizer/dualgpuopt/batch/smart_batch.py`:

- Length-aware inference scheduling
- Adaptive batch size optimization
- Token count-based grouping
- OOM recovery with cache management

## Batching Heuristics (Importance: 75)
Located in `dual_gpu_optimizer/dualgpuopt/batch/heuristics.py`:

- Power-of-two sequence bucketing
- Token ratio-based batch grouping
- GPU memory usage optimization
- Dynamic bucket allocation strategies

## Mixed Precision Policies (Importance: 70)
Located in `dual_gpu_optimizer/dualgpuopt/mpolicy.py`:

- FP32 precision maintenance for critical operations
- Dynamic dtype management
- Automatic precision scaling
- Operation-specific precision control

$END$