---
description: Technical specification for GPU optimization algorithms, tensor parallel splits, and memory distribution strategies in DualGPUOptimizer
globs: **/optimizer.py,**/gpu_info.py,**/gpu/**,**/gpu/*.py,**/layer_balance.py,**/memory/**,**/batch/*.py
alwaysApply: false
---


# gpu-optimization-algorithms

## Memory Distribution and Layer Balancing

### Tensor Parallel Distribution
The optimizer implements dynamic tensor parallel distribution across GPUs based on:
- Available VRAM per GPU
- Model architecture parameters (layers, hidden size, attention heads)
- Memory overhead per token for KV cache
- MoE (Mixture of Experts) scaling factors

File: `dualgpuopt/layer_balance.py`

### Layer Profiling System
- Profiles transformer layer execution times across sequence lengths
- Weights longer sequences (1024 tokens) at 80% vs shorter sequences (64 tokens) at 20%
- Caches profiling results per model to avoid redundant profiling
- Distributes layers between GPUs based on performance ratios

### Memory Monitoring and Recovery
Files: `dualgpuopt/memory/monitor.py`, `dualgpuopt/memory/recovery.py`

- Real-time GPU memory monitoring with configurable thresholds
- Memory alert levels: WARNING, CRITICAL, EMERGENCY
- Recovery strategies:
  - REDUCE_BATCH: Dynamically reduces batch size
  - CLEAR_CACHE: Frees CUDA cache
  - OFFLOAD: Moves layers to CPU
  - TERMINATE: Emergency process termination

### Smart Batching Algorithm
File: `dualgpuopt/batch/smart_batch.py`

- Groups sequences by length using pow2 bucketing
- Dynamically adjusts batch size based on:
  - Available GPU memory
  - Model memory profile
  - Current sequence lengths
- Implements backpressure mechanism to prevent OOM conditions

### Memory Prediction System
File: `dualgpuopt/memory/predictor.py`

- Maintains memory profiles for common models
- Projects memory growth using linear regression
- Calculates maximum safe context size based on:
  - GPU VRAM capacity
  - KV cache requirements
  - Memory overhead factors
  - MoE configuration

### Layer Balance Command Generation
File: `dualgpuopt/commands/gpu_commands.py`

- Generates optimized launch commands for:
  - llama.cpp with layer distribution
  - vLLM with tensor parallel configuration
- Sets environment variables for:
  - CUDA device mapping
  - NCCL peer-to-peer communication
  - Memory allocation strategy

$END$