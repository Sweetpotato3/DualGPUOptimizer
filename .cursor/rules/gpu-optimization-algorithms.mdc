---
description: Technical documentation for GPU optimization algorithms, memory allocation and tensor parallel computations
globs: **/optimizer.py,**/gpu_info.py,**/ctx_size.py,**/layer_balance.py
alwaysApply: false
---


# gpu-optimization-algorithms

## Memory Distribution System
Importance: 95

Core GPU memory allocation logic implemented in optimizer.py:
- Calculates tensor parallel fractions based on relative GPU memory capacities 
- Memory split optimization using available/total memory ratios
- Implements dynamic safety margins based on model architecture
- Model-specific memory requirement formulas for different LLM types
- Memory overhead calculations including tensor parallelism (20%) and system reserve (2GB)

## Layer Distribution Engine 
Importance: 90

Layer balancing algorithms in layer_balance.py:
- Distributes transformer layers across GPUs based on performance profiling
- Uses weighted execution time analysis combining:
  - Short sequence profiling (64 tokens, 20% weight)
  - Long sequence profiling (1024 tokens, 80% weight)
- Implements quota-based GPU allocation with configurable reserve ratios
- Prioritizes high-performance-differential layers to faster GPU within memory constraints

## Context Size Calculator
Importance: 85

Context window optimization in ctx_size.py:
- Calculates maximum safe token window based on:
  - Layer count 
  - KV head dimensions
  - Hidden layer size
  - MoE architecture factor
  - Available GPU memory
- Contains model-specific parameter mappings for major LLM architectures
- Implements safety margins for stable operation

## GPU Resource Monitor
Importance: 80

Hardware telemetry collection in gpu_info.py:
- Tracks real-time GPU utilization metrics
- Monitors memory allocation and fragmentation
- Calculates memory bandwidth consumption
- Reports PCIe throughput between GPUs
- Provides idle GPU detection with configurable thresholds

$END$