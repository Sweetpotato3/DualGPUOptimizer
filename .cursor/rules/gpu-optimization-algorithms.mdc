---
description: GPU optimization algorithms and memory management strategies for dual GPU setups with tensor parallel processing
globs: **/optimizer.py,**/gpu_info.py,**/gpu_models.py,**/layer_balance.py,**/gpu_commands.py,**/memory_monitor.py
alwaysApply: false
---


# gpu-optimization-algorithms

The gpu-optimization-algorithms aspect focuses on specialized algorithms for managing GPU memory distribution and tensor parallel processing across dual GPU setups.

## Core Memory Management System (memory_monitor.py)

GPU Memory Optimization with pre-defined model profiles:
```python
MODEL_PROFILES = {
  "llama2-70b": {
    "base_usage": 35GB,
    "per_batch": 350MB,
    "per_token": 18KB
  },
  "mixtral-8x7b": {
    "base_usage": 25GB, 
    "per_batch": 200MB,
    "per_token": 12KB
  }
}
```

Implements multi-tiered OOM prevention:
1. Cache clearing
2. Batch size reduction
3. Memory offloading
4. Process termination 

## Layer Distribution Algorithm (layer_balance.py)

Optimizes transformer layer distribution across GPUs:
- Profiles layer performance using short/long sequences
- Weighted profiling (20% short, 80% long sequences)
- Prioritizes faster GPU for compute-intensive layers
- Respects per-GPU VRAM quotas
- Creates contiguous layer blocks when possible

## Tensor Parallelism (optimizer.py)

Calculates optimal tensor parallel splits:
```python
def calculate_split_ratio(gpu1_mem, gpu2_mem):
  total = gpu1_mem + gpu2_mem
  ratio1 = gpu1_mem/total
  ratio2 = gpu2_mem/total
  return (ratio1, ratio2)
```

Memory allocation strategies:
- Proportional splits based on relative GPU memory
- Dynamic adjustment for model size
- Hardware-specific overhead calculations
- 20% memory safety buffer

## Key Files:
- dualgpuopt/optimizer.py
- dualgpuopt/layer_balance.py 
- dualgpuopt/memory_monitor.py
- dualgpuopt/gpu_info.py

$END$