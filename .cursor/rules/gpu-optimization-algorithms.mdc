---
description: Specification for GPU optimization algorithms, tensor parallelism, memory distribution and VRAM management components
globs: 
alwaysApply: false
---


# gpu-optimization-algorithms

## Core Optimization Components

### GPU Memory Split Calculator
- Calculates optimal tensor parallel splits across multiple GPUs based on relative VRAM capacities
- Implements weighted distribution algorithms to handle asymmetric GPU configurations 
- Dynamically adjusts split ratios based on model architecture requirements
- Located in `optimizer.py`

### Layer Distribution Manager
- Balances model layers across available GPUs using latency-aware distribution
- Implements contiguous block optimization to minimize inter-GPU communication
- Profiles layer execution times and adjusts distribution accordingly
- Located in `layer_balance.py`

### Memory Monitor & Recovery 
- Tracks GPU memory usage with configurable alert thresholds (warning at 80%, critical at 90%)
- Implements staged recovery strategies:
  1. Cache clearing
  2. Batch size reduction 
  3. Layer offloading
  4. Process termination
- Located in `memory/monitor.py`

### Batch Size Optimizer
- Dynamically calculates optimal batch sizes based on:
  - Available GPU memory
  - Model architecture 
  - Sequence length
  - KV cache requirements
- Implements length-aware batching for improved throughput
- Located in `batch/smart_batch.py`

### Memory Predictor
- Estimates memory requirements based on:
  - Base model size
  - Per-token memory usage
  - Attention mechanism overhead
  - MoE gating factors (if applicable)
- Provides safety margins to prevent OOM conditions
- Located in `memory/predictor.py`

## File Paths
```
dualgpuopt/
  optimizer.py
  layer_balance.py
  memory/
    monitor.py
    predictor.py
  batch/
    smart_batch.py
```

Importance Score: 95 - Core GPU optimization algorithms represent critical business logic for model deployment and execution

$END$