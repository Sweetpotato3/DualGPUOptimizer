---
description: Documentation of GPU memory and tensor optimization algorithms for ML model deployment across multiple GPUs.
globs: **/optimizer.py,**/gpu_info.py,**/gpu_commands.py,**/gpu_services/*,**/gpu_utils/*
alwaysApply: false
---


# gpu-optimization-algorithms

Core GPU Memory Distribution System:

1. Memory Split Calculator (optimizer.py)
- Calculates optimal memory splits for multi-GPU LLM deployments
- Memory allocation formula: available_vram * 0.9 - system_reserved
- Dynamic tensor fraction computation based on relative GPU memory sizes
- Enforces minimum 20% allocation per GPU rule
- Handles special cases for MoE models with expert sharding
- Validates context sizes against per-token memory requirements

2. Layer Distribution Engine (layer_balance.py)
- Weighted profiling using dual sequence lengths:
  * Short (64 tokens): 20% weight
  * Long (1024 tokens): 80% weight 
- Progressive layer allocation based on:
  * Per-layer latency measurements
  * Available GPU memory quotas
  * Historical performance patterns
- Block merging logic to reduce cross-GPU communication
- Special handling for embedding and output layers

3. Memory Recovery System (memory/recovery.py)
- Hierarchical recovery strategy:
  * Level 1: Cache clearing
  * Level 2: Batch size reduction
  * Level 3: Model offloading
  * Level 4: Process termination
- Maintains 85% memory usage target after recovery
- Implements 5-minute window for growth projections

4. Model-Specific Memory Profiles (model_profiles.py)
- Pre-configured memory requirements for common architectures:
  * Llama 2 (7B-70B)
  * Mistral-7B
  * Mixtral-8x7B
- KV cache scaling calculations per model type
- MoE-specific memory adjustments for expert activation patterns

5. Dynamic Batch Optimization (batch/smart_batch.py)
- Length-aware sequence batching
- Back-pressure system with configurable queue depths
- Automatic OOM recovery with cache purging
- Token-based batch splitting for GPU utilization
- Asynchronous execution with controlled intervals

Business Value Score: 95 - Core algorithms for GPU memory optimization and model deployment

File Paths:
- dualgpuopt/optimizer.py
- dualgpuopt/layer_balance.py
- dualgpuopt/memory/recovery.py
- dualgpuopt/model_profiles.py
- dualgpuopt/batch/smart_batch.py

$END$