---
description: Specification for GPU memory management, tensor splitting, and optimization algorithms for dual GPU setups.
globs: **/optimizer.py,**/gpu_info.py,**/layer_balance.py,**/batch/*.py
alwaysApply: false
---


# gpu-optimization-algorithms

## Core GPU Memory Distribution (Importance: 95)
Location: dual_gpu_optimizer/dualgpuopt/optimizer.py

The GPU memory distribution system implements specialized algorithms for:
- Dynamic tensor splitting across dual GPUs based on memory capacity ratios
- Automatic rebalancing when memory pressure exceeds thresholds
- Safety reserve calculation that maintains 10% free memory per GPU
- Adaptive split ratio adjustments based on model layer distributions

## Layer Balancing Algorithm (Importance: 90)
Location: dual_gpu_optimizer/dualgpuopt/layer_balance.py

Implements intelligent layer distribution across GPUs:
- Weighted profiling using dual sequence lengths (64/1024 tokens)
- Layer assignment prioritization based on computational intensity
- Memory quota enforcement while maximizing GPU utilization
- Special handling for attention layers with varying sequence scaling

## Smart Batch Processing (Importance: 85)
Location: dual_gpu_optimizer/dualgpuopt/batch/smart_batch.py

Specialized batching system for dual GPU inference:
- Length-aware scheduling with token-based batch sizing
- Back-pressure mechanisms preventing RAM overflow
- Automatic OOM recovery with intelligent cache clearing
- Bucket-based request grouping optimized for dual GPU setups

## Memory Policy Management (Importance: 80)
Location: dual_gpu_optimizer/dualgpuopt/mpolicy.py

Implements mixed precision policies:
- FP32 precision preservation for critical operations
- Context-aware dtype selection for memory optimization
- Safety guards for numerical stability in dual GPU scenarios

## GPU Resource Monitoring (Importance: 75)
Location: dual_gpu_optimizer/dualgpuopt/gpu_info.py

Specialized monitoring system tracking:
- Memory efficiency patterns across GPU pairs
- Utilization imbalances between devices
- Architecture-aware CUDA core calculations
- PCIe bandwidth monitoring for inter-GPU transfer optimization

$END$