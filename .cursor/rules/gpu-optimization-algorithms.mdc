---
description: Defines GPU memory distribution algorithms, tensor parallel splits calculation, and memory allocation strategies
globs: 
alwaysApply: false
---


# gpu-optimization-algorithms

Core GPU Memory Distribution Logic:

1. Memory Split Calculator (optimizer.py)
- Implements split ratio algorithm for dual GPU memory allocation
- Calculates optimal tensor parallel split based on:
  * Available GPU VRAM 
  * Model architecture parameters
  * KV cache requirements
  * Layer distribution needs
- Enforces memory safety margins (10% minimum free VRAM)
- Supports asymmetric GPU configurations with weighted distribution

2. Memory Pattern Analysis (memory/profiler.py)
- Memory leak detection using sliding window analysis
- Two-tier detection system:
  * Rapid growth detection for memory spikes
  * Sustained growth monitoring for gradual leaks
- Session-based profiling with inference boundary tracking
- Classification of memory events into business categories

3. Smart Batching System (batch/smart_batch.py) 
- Length-aware batch scheduling for GPU inference
- Token budget management (max 16384 tokens/batch)
- Dynamic batch sizing with OOM prevention
- Backpressure mechanism for memory pressure

4. Layer Distribution Optimizer
- Weighted profiling with dual sequence analysis:
  * Short sequence (64 tokens) - 20% weight
  * Long sequence (1024 tokens) - 80% weight  
- Block optimization with 3-layer minimum groups
- Layer placement rules:
  * Input embeddings to first/fast GPU
  * Output components to last/slow GPU

5. Recovery Strategy System (memory/recovery.py)
- Progressive memory recovery strategies:
  * REDUCE_BATCH: Lower batch size
  * CLEAR_CACHE: Force cache clearing  
  * OFFLOAD: Move data to CPU
  * TERMINATE: Stop low priority processes
- Exponential backoff for recovery attempts
- Memory thresholds for triggering recovery

File Paths:
```
dualgpuopt/optimizer.py
dualgpuopt/memory/profiler.py
dualgpuopt/batch/smart_batch.py
dualgpuopt/memory/recovery.py
```

$END$