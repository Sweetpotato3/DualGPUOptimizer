---
description: Applies to GPU optimization algorithms, memory management, and workload distribution across multiple GPUs
globs: dualgpuopt/optimizer.py,dualgpuopt/gpu_info.py,dualgpuopt/layer_balance.py
alwaysApply: false
---


# gpu-optimization-algorithms

## Memory Distribution Algorithm
Score: 95
- Calculates optimal memory splits between GPUs based on relative VRAM capacity
- Reserves system overhead (2GB base + 20% tensor parallel overhead)
- Implements KV cache memory tracking with 2.0x multiplier 
- Maintains 10% safety margin for dynamic allocations

## Layer Balancing System
Score: 90
- Optimizes layer distribution across GPUs using weighted execution profiles
- Profiles layer performance at sequence lengths 64 and 1024
- Prioritizes faster GPU for computationally intensive layers
- Allocates layers based on relative GPU memory quotas and capabilities

## Tensor Split Calculation
Score: 85
- Determines optimal tensor parallel splits for asymmetric GPU configurations 
- Adapts split ratios based on available VRAM per device
- Handles specialized MoE model factors (1.05x memory overhead)
- Calculates safe context lengths for different model architectures

## Context Size Optimization
Score: 80
- Calculates maximum safe context window based on:
  - Transformer architecture parameters (layers, heads, dimensions) 
  - Available GPU memory across devices
  - Model-specific MoE factors
- Contains preset parameters for LLaMA-2, Mistral, Mixtral models

Key files implementing core logic:
- dualgpuopt/optimizer.py: Memory distribution and tensor splits
- dualgpuopt/layer_balance.py: Layer distribution algorithms
- dualgpuopt/ctx_size.py: Context size calculation

$END$