---
description: Specification for GPU memory optimization, tensor splitting algorithms, and distribution calculations for multi-GPU LLM inference
globs: **/optimizer.py,**/gpu_info.py,**/layer_balance.py
alwaysApply: false
---


# gpu-optimization-algorithms

Key Memory Optimization Components:

1. Layer Distribution Algorithm (layer_balance.py)
- Dynamic layer balancing across GPUs based on weighted performance ratios
- Profiling using sequence lengths of 64 and 1024 tokens (20%/80% weights)
- Block optimization with 3-layer minimum for preventing fragmentation
- Specialized handling for input embeddings and output components

2. Memory Split Calculator (optimizer.py)
- Tensor parallel fraction calculation based on relative GPU memory sizes
- Memory requirement estimation incorporating:
  * Base model weights
  * KV cache overhead (2.0x factor)
  * Tensor parallelism overhead (20%)
  * Minimum context size enforcement (128 tokens)
  * Safety margin (10% default)

3. Model-Specific Optimizations
- Context size constraints per architecture:
  * 70B models: 4096 max tokens
  * Mixtral: 8192 max tokens  
  * 13B models: 12288 max tokens
  * Standard models: 16384 max tokens

4. Memory Management Rules
- Progressive memory reclamation:
  * CACHE_ONLY: Basic PyTorch cache clearing
  * CLOCK_RESET: GPU clock manipulation
  * FULL_RESET: Comprehensive memory reset
  * SYSTEM_CMD: OS-specific commands

Implementation Score: 95
Rationale: Core optimization algorithms for multi-GPU distribution and memory management

File Paths:
- dualgpuopt/optimizer.py
- dualgpuopt/layer_balance.py
- dualgpuopt/gpu_info.py

$END$