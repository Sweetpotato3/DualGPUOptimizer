---
description: Specification for GPU memory distribution and optimization algorithms, tensor parallel splits, and memory allocation strategies
globs: dualgpuopt/optimizer.py,dualgpuopt/gpu_info.py,dualgpuopt/mpolicy.py,dualgpuopt/layer_balance.py,dualgpuopt/memory/**
alwaysApply: false
---


# gpu-optimization-algorithms

The GPU optimization and memory allocation algorithms comprise several key components:

## Layer Distribution Algorithm
- GPU-aware layer distribution system with latency profiling across sequence lengths
- Assigns transformer model layers between GPUs using execution time measurements
- Uses weighted profiling: 20% short sequences (64 tokens), 80% long sequences (1024 tokens)
- Maintains reserve ratio (default 0.9) to prevent GPU memory exhaustion
- Implements block merging for layer groups smaller than 3 layers

File: `dualgpuopt/layer_balance.py`

## Memory Split Calculator
- Calculates optimal memory distribution between GPUs based on model architecture
- Implements KV cache sizing with architecture-specific factors:
  - MQA models: 0.25x multiplier
  - GQA models: 0.5x multiplier
  - Standard attention: 1x multiplier
- Accounts for tensor parallelism overhead in memory estimates
- Provides framework-specific split configurations for llama.cpp and vLLM

File: `dualgpuopt/optimizer.py`

## GPU Memory Monitoring
- Real-time memory tracking with alert thresholds:
  - Emergency: ≥95% memory usage
  - Critical: ≥90% memory usage
  - Warning: ≥75% memory usage
- Implements memory reclamation with multi-tier strategy:
  - Cache clearing
  - GPU clock reset
  - Full memory reset
  - System-level cleanup
- Tracks successful reclamation above 256MB threshold

File: `dualgpuopt/memory/monitor.py`

## Memory Profiling
- Session-based memory tracking during inference
- Detects memory leaks through two mechanisms:
  - Rapid growth detection (immediate alerts)
  - Gradual leak tracking (sustained growth)
- Memory change threshold of 5MB for leak reporting
- 30-second cooldown between leak alerts per GPU
- Correlates memory patterns with inference stages

File: `dualgpuopt/memory/profiler.py`

## Mixed Precision Policies
- Implements optimized dtype policies for different operations:
  - FP32: LayerNorm, Softmax, Residuals
  - FP16/BF16: Matrix multiplications
  - INT8/INT4: Weight storage
- Autocast context manager preserves precision for critical ops
- Framework-specific command generation for precision settings

File: `dualgpuopt/mpolicy.py`

$END$
