---
description: Specification for GPU optimization algorithms, memory management, and tensor parallel splitting calculations
globs: **/optimizer.py,**/gpu_info.py,**/gpu/*.py,**/memory/*.py
alwaysApply: false
---


# gpu-optimization-algorithms

## Memory Management and Distribution

The optimizer implements specialized memory management for dual GPU configurations:

1. Memory Split Calculation:
```python
memory_split = max_gpu_memory * tensor_fraction
```
- Calculates optimal memory distribution across GPUs
- Accounts for model size, batch size, and KV cache requirements
- Implements safety margins to prevent OOM conditions
- Adjusts splits based on relative GPU memory capacities

File: `dualgpuopt/optimizer.py`

2. Layer Distribution:
- Balances transformer layers across GPUs based on memory requirements
- Factors in KV cache sizing for attention mechanisms
- Handles special cases for MoE (Mixture of Experts) architectures
- Provides fallback distribution for asymmetric GPU configurations

File: `dualgpuopt/layer_balance.py`

3. Context Length Optimization:
- Dynamic calculation of maximum safe context length
- Adjusts for model architecture (hidden size, layers, heads)
- Accounts for MQA/GQA attention reduction factors
- Implements architecture-specific memory estimation

File: `dualgpuopt/ctx_size.py`

## Memory Monitoring and Recovery

1. Memory Alert System:
- Triggers alerts at configurable memory thresholds
- Implements exponential backoff for recovery attempts
- Provides memory reclamation strategies:
  - CUDA cache clearing
  - Gradient checkpointing
  - Layer offloading
  - Batch size reduction

File: `dualgpuopt/memory/monitor.py`

2. Memory Usage Prediction:
- Projects memory requirements based on:
  - Model architecture parameters
  - Batch size and sequence length
  - Attention mechanism type
  - Number of experts in MoE models

File: `dualgpuopt/memory/predictor.py`

## Tensor Parallel Optimization

1. Split Calculation:
- Determines optimal tensor parallel size based on:
  - Available GPU memory
  - Model hidden dimensions
  - Number of attention heads
  - MoE gating factors

2. Memory Efficiency:
- Implements gradient synchronization optimization
- Manages activation checkpointing for memory efficiency
- Provides tensor parallel awareness for optimizer state

File: `dualgpuopt/optimizer.py`

## Model Architecture Detection

1. Architecture Parameter Extraction:
- Pattern matching for common model configurations
- Automatic detection of:
  - Hidden size
  - Number of layers
  - Attention heads
  - KV heads
  - MoE configurations

2. Memory Requirement Calculation:
- Per-token memory estimation
- Activation memory modeling
- KV cache sizing
- Optimizer state requirements

File: `dualgpuopt/ctx_size.py`

$END$