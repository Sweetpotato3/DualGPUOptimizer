---
description: Specialized GPU memory distribution algorithms, tensor parallel splits calculation, and memory allocation strategies.
globs: **/optimizer.py,**/gpu_info.py
alwaysApply: false
---


# gpu-optimization-algorithms

## Core GPU Memory Distribution System
The optimizer implements advanced memory distribution algorithms for multi-GPU deep learning model execution. Key components:

1. Memory Split Generation
- Located in: `dualgpuopt/optimizer.py`
- Calculates optimal GPU memory splits based on detected GPU configurations
- Generates split strings used by model frameworks like llama.cpp and vLLM
- Importance Score: 95

2. Tensor Parallel Fraction Calculator
- Located in: `dualgpuopt/optimizer.py`  
- Determines optimal tensor parallel fractions for model distribution
- Accounts for varying GPU memory capacities
- Calculates balanced memory allocation ratios
- Importance Score: 90

3. GPU Memory Probing
- Located in: `dualgpuopt/gpu_info.py`
- Collects detailed GPU memory metrics including:
  - Available VRAM
  - Current memory utilization
  - Memory bandwidth capabilities
- Utilizes parallel probing for enhanced detection
- Importance Score: 85

4. Framework-Specific Command Generation 
- Located in: `dualgpuopt/optimizer.py`
- Generates optimized command strings for:
  - llama.cpp tensor splits
  - vLLM memory distribution
  - Environment variable configurations
- Incorporates calculated memory splits and tensor fractions
- Importance Score: 80

5. Mock GPU Memory Simulation
- Located in: `dualgpuopt/gpu_info.py`
- Simulates GPU memory configurations for testing
- Generates realistic memory distribution scenarios
- Importance Score: 45

The system prioritizes balanced memory distribution while accounting for heterogeneous GPU configurations. Memory splits are calculated based on relative VRAM capacities and adjusted for optimal tensor parallel execution.

$END$