---
description: GPU memory distribution algorithms, tensor parallel splits, and optimization strategies for large language model deployment
globs: **/optimizer.py,**/gpu_info.py,**/layer_balance.py,**/memory/*.py,**/batch/*.py,**/services/*.py
alwaysApply: false
---


# gpu-optimization-algorithms

Key algorithms for GPU resource optimization and model distribution:

1. GPU Memory Split Calculator (optimizer.py)
```python
def calculate_gpu_splits():
    # Calculate optimal memory distribution across GPUs
    per_token_memory = model.hidden_size * model.num_layers * kv_head_ratio
    safety_margin = 0.1  # 10% safety buffer
    vram_per_gpu = get_available_memory() * (1 - safety_margin)
    
    return distribute_memory(vram_per_gpu, per_token_memory)
```

2. Layer Balance Optimizer (layer_balance.py)
```python
def optimize_layer_distribution():
    # Profile layer performance with dual sequence lengths
    short_perf = profile_layers(seq_len=64)  # 20% weight
    long_perf = profile_layers(seq_len=1024) # 80% weight
    weighted_perf = 0.2 * short_perf + 0.8 * long_perf
    
    # Calculate GPU quotas based on performance ratios
    gpu_quotas = calculate_quotas(weighted_perf)
    return distribute_layers(gpu_quotas)
```

3. Memory Usage Predictor (memory/predictor.py)
- Calculates per-token memory requirements:
  * Base model memory
  * KV cache scaling
  * Activation memory
  * MoE overhead for expert models

4. Smart Batch Scheduler (batch/smart_batch.py)
- Groups similar-length sequences
- Dynamic batch size adjustment
- OOM prevention with 25% reduction on failure
- Recovery mechanism with 5-batch success requirement

Core Business Rules:

1. GPU Memory Management:
- Minimum 20% model allocation per GPU
- 10% safety margin for dynamic allocations
- Non-linear scaling for KV cache memory

2. Layer Distribution:
- Long sequence performance weighted at 80%
- Short sequence performance at 20%
- Contiguous block optimization to reduce transfers

3. Resource Optimization:
- Automatic tensor parallel sizing
- Dynamic split ratio calculation
- Framework-specific command generation
- Model-aware memory estimation

Key Files:
- optimizer.py: Core memory distribution logic
- layer_balance.py: Layer optimization algorithms
- memory/predictor.py: Memory requirement calculations
- batch/smart_batch.py: Batch scheduling optimization

$END$