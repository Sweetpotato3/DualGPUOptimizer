---
description: Handles GPU memory optimization, tensor parallelism, and memory allocation strategies
globs: **/optimizer.py,**/gpu_info.py,**/ctx_size.py,**/layer_balance.py
alwaysApply: false
---


# gpu-optimization-algorithms

## Memory Distribution Algorithm
The optimizer implements GPU memory distribution through tensor parallelism calculation and split ratios:

```python
- Memory split calculation based on total available VRAM across GPUs
- Tensor parallel size determination using GPU count and model requirements  
- Dynamic allocation balancing based on GPU capabilities
```

File: dual_gpu_optimizer/dualgpuopt/optimizer.py

## Layer Distribution System 
Implements latency-aware layer redistribution:

- Profiles execution time per layer across available GPUs
- Redistributes layers based on memory usage and latency metrics
- Generates device mapping JSON for layer assignments
- Adapts distribution based on real-time GPU telemetry

File: dual_gpu_optimizer/dualgpuopt/layer_balance.py

## Context Size Calculator
Calculates maximum safe context length:

- Analyzes available GPU memory across devices
- Considers model parameters (layers, heads, dimensions)
- Accounts for mixed precision and optimization settings
- Provides recommended context size per GPU configuration

File: dual_gpu_optimizer/dualgpuopt/ctx_size.py

## GPU Memory Monitoring
Real-time GPU memory tracking and optimization:

- Collects detailed metrics on memory usage and allocation
- Monitors VRAM fragmentation and utilization 
- Provides memory availability stats for optimization decisions
- Tracks PCIe bandwidth usage between GPUs

File: dual_gpu_optimizer/dualgpuopt/gpu_info.py

Importance Scores:
- Memory Distribution Algorithm: 95 (Core optimization logic)
- Layer Distribution System: 90 (Critical for multi-GPU performance)
- Context Size Calculator: 85 (Key for memory management)
- GPU Memory Monitoring: 80 (Essential telemetry for optimization)

$END$