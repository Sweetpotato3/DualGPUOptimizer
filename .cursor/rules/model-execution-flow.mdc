---
description: Handles model execution workflow configuration and GPU resource allocation for LLM deployment
globs: **/launcher.py,**/runner.py,**/optimizer.py,**/gpu_info.py,**/commands/*.py
alwaysApply: false
---


# model-execution-flow

Core Model Execution Components:

1. Framework-Specific Command Generation (80/100)
- Generates optimized command lines for different ML frameworks:
  * llama.cpp: GPU layer splits and context size parameters
  * vLLM: Tensor parallel size and memory utilization config
- Located in: dualgpuopt/launcher.py, dualgpuopt/commands/gpu_commands.py

2. Memory Management Strategy (95/100)
- Implements progressive memory management:
  * OOM detection with automatic recovery
  * Memory pressure monitoring with thresholds
  * CUDA cache clearing on threshold breach
  * Dynamic batch size adjustment based on memory availability
- Located in: dualgpuopt/memory_monitor.py

3. GPU Layer Distribution (90/100)
- Dynamic layer balancing across multiple GPUs using:
  * Performance weights (64 tokens: 0.2, 1024 tokens: 0.8)
  * Memory quota-based distribution
  * Contiguous block formation to minimize transitions
- Located in: dualgpuopt/layer_balance.py

4. Model Parameter Analysis (85/100)
- Extracts model parameters from filenames:
  * Layer count and dimensions
  * KV head configuration
  * Context size optimization
  * Batch size calculations
- Located in: dualgpuopt/optimizer.py

5. Process Management (75/100)
- Non-blocking subprocess handling for model inference
- Specialized management for llama.cpp and vLLM processes
- Thread-safe output streaming
- Located in: dualgpuopt/runner.py

6. Resource Monitoring (70/100)
- Real-time metrics collection:
  * Tokens/second throughput
  * GPU memory pressure
  * Temperature and utilization
  * Performance degradation detection
- Located in: dualgpuopt/telemetry.py

The system employs a layered approach to model execution, with specialized handling for different frameworks and dynamic resource allocation based on GPU capabilities and model requirements.

$END$