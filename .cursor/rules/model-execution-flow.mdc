---
description: Documents LLM execution workflows, command generation, and GPU resource management for dual GPU optimization
globs: **/dualgpuopt/runner.py,**/dualgpuopt/optimizer.py,**/commands/**,**/batch/**
alwaysApply: false
---


# model-execution-flow

The model execution flow implements specialized handling of LLM workloads across dual GPU configurations:

Core Execution Components (Importance: 95):

1. Command Generation Pipeline
- Produces optimized commands for llama.cpp:
  ```
  --gpu-split <ratio> --n-gpu-layers <count> --ctx-size <window>
  ```
- Generates vLLM tensor parallelism settings:
  ```
  tensor_parallel_size=<n> max_context_len=<size>
  ```
- Dynamically calculates memory splits based on available GPU VRAM

2. Batch Processing Workflow (Importance: 90)
- Length-aware sequence batching with 20% memory reserve
- Token limit management (max 8192 tokens default)
- Dynamic batch size scaling based on:
  - Available GPU memory
  - Model parameter count
  - Sequence length distribution
  - Memory overhead estimations

3. GPU Resource Allocation Flow (Importance: 85)
- Real-time GPU utilization monitoring
- Memory distribution across GPUs:
  - Primary allocation based on VRAM ratios
  - Secondary fine-tuning based on utilization
  - Temperature-aware load balancing
  - PCIe bandwidth optimization

4. Model Context Management (Importance: 80)
- Automatic context size calculation based on:
  - Layer count and dimensions
  - KV head configuration 
  - Precision settings (4/8/16-bit)
  - MoE scaling factors
- Dynamic adjustment based on memory availability

Execution Paths:
1. Pre-execution:
   - GPU capability detection
   - Memory availability checks
   - Command parameter generation
   
2. Runtime:
   - Batch queue management
   - Memory utilization monitoring
   - Temperature-based throttling
   - Load rebalancing

3. Error Recovery:
   - OOM handling with cache purge
   - Batch size reduction
   - Automatic retries with reduced parameters

The system prioritizes stable execution while maximizing GPU utilization through intelligent resource allocation and dynamic batch management.

$END$