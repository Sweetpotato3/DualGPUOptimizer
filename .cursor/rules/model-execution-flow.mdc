---
description: Defines how AI models are executed, optimized and balanced across multiple GPUs including command generation and resource allocation.
globs: **/optimizer.py,**/runner.py,**/layer_balance.py,**/ctx_size.py,**/mpolicy.py
alwaysApply: false
---


# model-execution-flow

The model execution flow consists of several key components that work together to optimize and execute AI models across multiple GPUs:

### GPU Layer Distribution (Importance: 95)
Located in `dual_gpu_optimizer/dualgpuopt/layer_balance.py`:
- Implements adaptive latency-aware layer redistribution algorithm
- Profiles layer execution times to identify fast/slow layers
- Generates device maps for optimal layer placement across GPUs
- Balances layers based on execution speed and available VRAM

### Context Size Management (Importance: 90)
Located in `dual_gpu_optimizer/dualgpuopt/ctx_size.py`:
- Calculates maximum safe context length based on GPU memory and model parameters
- Dynamically adjusts context sizes to optimize memory usage
- Estimates model parameters from model names for automated configuration
- Supports models including Mixtral, Llama 2, and Mistral

### Command Generation (Importance: 85)
Located in `dual_gpu_optimizer/dualgpuopt/optimizer.py`:
- Generates framework-specific commands for llama.cpp and vLLM
- Calculates optimal GPU split strings and tensor parallel sizes
- Creates environment files with CUDA device configurations
- Determines tensor fractions based on available GPU memory

### Mixed Precision Execution (Importance: 80)
Located in `dual_gpu_optimizer/dualgpuopt/mpolicy.py`:
- Manages mixed precision inference with automatic fallback to FP32
- Provides context managers for autocast operations
- Handles GradScaler integration for mixed precision training

### Model Runner (Importance: 75)
Located in `dual_gpu_optimizer/dualgpuopt/runner.py`:
- Executes model inference across distributed GPU setup
- Handles tensor parallel synchronization
- Manages model loading and unloading
- Provides error recovery for OOM conditions

$END$