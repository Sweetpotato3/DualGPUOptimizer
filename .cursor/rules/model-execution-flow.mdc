---
description: Specification for LLM model execution workflows, command generation, and GPU resource management
globs: **/optimizer.py,**/runner.py,**/gpu_info.py,**/telemetry.py
alwaysApply: false
---


# model-execution-flow

## Core Model Execution Components 
Importance Score: 95

The model execution workflow is handled through several key components:

1. Command Generation Engine
- Generates execution commands for llama.cpp and vLLM frameworks
- Configures environment variables for GPU memory allocation
- Creates split strings for multi-GPU tensor distribution
- Sets data types and tensor parallel sizes based on available GPUs

2. GPU Resource Management
- Calculates tensor fractions for balanced GPU memory distribution
- Detects and validates available GPU devices through NVML
- Generates GPU split configurations for optimal resource utilization
- Supports mock GPU data for testing environments

3. Model Execution Flow
- Initializes GPU monitoring and telemetry collection
- Configures CUDA visible devices based on optimization parameters
- Streams real-time GPU utilization metrics during model execution
- Manages environment file generation for runtime configurations

## Key Integration Points
Importance Score: 85

The execution flow integrates with:

1. Telemetry System
- Collects GPU load, memory usage, and PCIe throughput metrics
- Streams real-time utilization data during model execution
- Monitors GPU idle states for resource optimization

2. Framework Adapters
- llama.cpp command generation with GPU split configuration
- vLLM execution parameters with tensor parallel distribution
- Dynamic adaptation based on GPU availability and memory capacity

## Resource Allocation Logic
Importance Score: 80

1. GPU Split Configuration
- Generates comma-separated strings for GPU memory allocation
- Calculates relative tensor fractions for memory distribution
- Creates environment files with CUDA device configurations

2. Monitoring and Optimization
- Real-time GPU utilization tracking
- Idle resource detection and notification
- Dynamic resource reallocation based on usage patterns

$END$