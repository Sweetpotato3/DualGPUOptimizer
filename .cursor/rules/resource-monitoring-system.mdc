---
description: Monitors dual GPU performance metrics, utilization, and resource allocation for optimization
globs: **/telemetry.py,**/tray.py,**/metrics.py,**/gpu_info.py
alwaysApply: false
---


# resource-monitoring-system

Core telemetry system components:

1. GPU Metrics Collection (telemetry.py):
- Comprehensive GPU performance monitoring metrics:
  - Memory utilization and bandwidth 
  - PCIe RX/TX traffic
  - Temperature, power, clock metrics
  - Fan speeds and load percentages
- Real-time middleware pipeline for metric processing/distribution
- Non-blocking telemetry collection with failover to mock mode
- Event-based metric publishing to application monitoring bus

2. Idle Resource Detection (tray.py):
- GPU idle state monitoring with configurable thresholds:
  - Utilization below 30% trigger point
  - 5-minute minimum idle duration
  - Per-GPU idle tracking
- Resource optimization recommendations generation
- Notification system for underutilized GPU resources

3. Performance Analysis (metrics.py):
- Batch latency tracking for end-to-end processing
- Queue depth monitoring for request handling
- Prometheus integration for metrics collection
- Rolling 60-second history window for trend analysis

4. Hardware Info Collection (gpu_info.py):
- Architecture-specific CUDA core detection
- Memory capacity and bandwidth profiling
- Temperature threshold monitoring:
  - Warning level: 80째C
  - Critical level: 90째C
- Multi-GPU synchronization and correlation

Key monitoring thresholds:
```python
UTIL_LOW = 30%      # Idle detection trigger
UTIL_MEDIUM = 60%   # Normal operation range  
UTIL_HIGH = 90%     # High load warning
TEMP_WARNING = 80째C
TEMP_CRITICAL = 90째C
```

The system maintains continuous monitoring of dual GPU setups with emphasis on:
- Resource utilization efficiency
- Thermal management
- Memory allocation optimization
- Performance bottleneck detection

All metrics are processed through a priority-based event pipeline enabling real-time optimization decisions and resource reallocation.

$END$