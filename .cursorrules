
START SPECIFICATION:
---
description: Use when documenting high-level architecture of GPU optimization systems, particularly those focused on dual-GPU configurations and machine learning model execution
globs: *.py,*.code-workspace
alwaysApply: false
---


# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


The DualGPUOptimizer implements a specialized system for managing and optimizing dual-GPU configurations with four core business domains:

1. GPU Optimization Engine (Importance: 95)
- Memory splitting algorithms for distributing ML model workloads
- Tensor fraction calculations based on GPU memory capacities
- Environment configuration generation for LLaMA and vLLM frameworks
- Located in: dual_gpu_optimizer/dualgpuopt/optimizer.py

2. Hardware Control System (Importance: 90)
- GPU overclocking management with safety limits
- Power limit and fan speed control
- State preservation for rollback operations
- Located in: dual_gpu_optimizer/dualgpuopt/commands/gpu_commands.py

3. Performance Monitoring (Importance: 85)
- Real-time GPU metrics tracking
- PCIe bandwidth monitoring with dynamic unit scaling
- Temperature and power consumption analysis
- Located in: dual_gpu_optimizer/dualgpuopt/telemetry.py

4. Model Execution Framework (Importance: 80)
- Dual-mode execution system for llama.cpp and vLLM
- Dynamic GPU split configurations
- Framework-specific command generation
- Located in: dual_gpu_optimizer/dualgpuopt/gui/launcher.py

Key Business Rules:
1. GPU memory allocation must optimize for model requirements
2. Overclocking changes require preservation for rollback
3. Hardware failures trigger automatic mock mode
4. Temperature thresholds map to 0-100Â°C scale
5. Power usage normalized to 400W baseline
6. Performance history maintained in 60-sample windows

The system specifically targets AI/ML workload optimization across dual GPU configurations, with emphasis on memory management, hardware safety, and framework-specific optimizations.

$END$
END SPECIFICATION