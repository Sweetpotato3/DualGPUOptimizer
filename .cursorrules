
START SPECIFICATION:
---
description: Use this overview documentation when examining a GPU optimization system for large language models that handles dual GPU configurations, memory management, and performance monitoring.
globs: *.py,*.code-workspace
alwaysApply: false
---


# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


The Dual GPU Optimizer implements specialized logic for running large language models across multiple GPUs with three core business areas:

1. GPU Memory and Resource Management (Importance: 95)
- Calculates optimal tensor split ratios based on GPU memory capacities
- Implements model-specific context size management considering:
  - Layer counts, KV heads, and head dimensions
  - Precision types (16-bit, 8-bit QLoRA, 4-bit GPTQ)
  - MoE factors for specialized models
- Handles real-time memory allocation and recovery

Key files:
- dualgpuopt/ctx_size.py
- dualgpuopt/optimizer.py

2. GPU Performance Monitoring (Importance: 85)
- Tracks critical GPU metrics:
  - Utilization and memory usage
  - Temperature and power draw
  - PCIe bandwidth
  - Clock speeds
- Implements idle detection with configurable thresholds
- Maintains 60-sample rolling window for performance trends

Key files:
- dualgpuopt/telemetry.py
- dualgpuopt/gui/dashboard.py

3. Layer Distribution System (Importance: 90)
- Balances model layers across GPUs using:
  - Dual sequence length testing (64/1024 tokens)
  - Weighted scoring system for throughput optimization
  - VRAM quota management
- Implements specialized mixed precision strategies:
  - FP32 for critical operations
  - Automatic precision scaling
  - Framework-specific optimizations for llama.cpp and vLLM

Key files:
- dualgpuopt/layer_balance.py
- dualgpuopt/mpolicy.py

The system integrates these components through an event-driven architecture that coordinates GPU resource allocation, monitors performance, and optimizes model deployment across multiple GPUs.

$END$
END SPECIFICATION