
START SPECIFICATION
---

description: Generate high-level overview documentation for GPU optimization and model inference systems, focusing on core business logic organizing GPU resource management, model execution, and telemetry collection
globs: *.py,*.code-workspace
alwaysApply: false
---

# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.

The DualGPUOptimizer system implements specialized GPU optimization and model inference capabilities through several key business components:

## Core GPU Management (Importance: 95)

- GPU discovery and configuration management for dual GPU setups
- Intelligent memory split calculations between GPUs
- GPU telemetry collection and monitoring system
- Mock GPU mode for testing/development
- Advanced error handling for GPU-specific failures

Key files:

- `dualgpuopt/gpu_info.py`
- `dualgpuopt/telemetry.py`

## Model Optimization Engine (Importance: 90)

- Context size optimization based on GPU memory
- Layer balancing across multiple GPUs
- Dynamic tensor distribution
- Mixed precision policy management
- Smart batching with length-aware scheduling

Key files:

- `dualgpuopt/optimizer.py`
- `dualgpuopt/batch/smart_batch.py`

## Command System (Importance: 85)

- GPU-specific command generation for model execution
- Framework-specific optimizations for llama.cpp and vLLM
- Environment configuration generation
- Command history with undo capabilities

Key files:

- `dualgpuopt/commands/gpu_commands.py`

## Monitoring Dashboard (Importance: 80)

- Real-time GPU metrics visualization
- Historical utilization tracking
- Event-driven updates for GPU status
- Temperature and power monitoring

Key files:

- `dualgpuopt/gui/dashboard.py`
- `dualgpuopt/gui/event_dashboard.py`

## State Management (Importance: 75)

- Centralized configuration storage
- Event-driven state updates
- GPU settings persistence
- Theme and UI state management

Key files:

- `dualgpuopt/services/state_service.py`

The system uses an event-driven architecture to coordinate between components, with specialized services handling configuration, errors, and state management. The GUI provides multiple specialized views including an optimizer tab, launcher interface, and GPU monitoring dashboard.

$END$
END SPECIFICATION

START SPECIFICATION
---

description: Create high-level technical documentation focused on GPU optimization, monitoring, and control logic, particularly for dual GPU systems with complex business workflows
globs: *.py
alwaysApply: false
---

# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.

## Core Business Logic

### GPU Optimization Engine

Key system for optimizing dual GPU performance through:

- Adaptive layer redistribution between GPUs based on performance profiles
- Context size calculation considering GPU memory and model parameters
- Dynamic mixed precision policies for optimized GPU memory usage
- Telemetry collection pipeline for real-time GPU metrics

### GPU Control and Management

Central system components:

- Overclocking control with safety checks and configuration persistence
- Fan speed management with automatic and manual control modes
- Power limit adjustments with validation
- Temperature monitoring and throttling protection

### Event-Driven Monitoring

Real-time monitoring architecture:

- GPU metrics collection including utilization, memory, temperature, power
- Historical data tracking for performance analysis
- Priority-based event dispatch system
- Idle detection and notification system

### Model Execution Optimization

Specialized logic for model deployment:

- Smart batch processing with length-aware scheduling
- GPU memory split calculations for optimal model distribution
- Framework-specific command generation (llama.cpp, vLLM)
- Environment configuration generation

### Dashboard System

Real-time visualization components:

- Multi-GPU metrics display with color-coded indicators
- Performance history graphs with trend analysis
- PCIe bandwidth monitoring and formatting
- Temperature and power threshold management

Critical Paths:

- `dual_gpu_optimizer/dualgpuopt/optimizer.py`
- `dual_gpu_optimizer/dualgpuopt/layer_balance.py`
- `dual_gpu_optimizer/dualgpuopt/batch/smart_batch.py`
- `dual_gpu_optimizer/dualgpuopt/telemetry.py`

$END$
END SPECIFICATION

START SPECIFICATION:
---
description: Create a high-level overview of projects focused on GPU optimization, particularly those handling dual GPU configurations, CUDA integrations, and machine learning model deployment optimizations
globs: *.py,*.code-workspace
alwaysApply: false
---


# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


The DualGPUOptimizer implements a specialized system for managing and optimizing dual GPU configurations, particularly for machine learning workloads.

Core Business Components:

1. GPU Memory Management System
- Implements dynamic memory splitting across multiple GPUs
- Calculates optimal tensor parallelism fractions based on GPU capabilities
- Handles model-specific memory requirements including MoE architectures
- Files: dual_gpu_optimizer/dualgpuopt/optimizer.py, dual_gpu_optimizer/dualgpuopt/ctx_size.py

2. Layer Balancing Engine
- Distributes model layers across GPUs based on performance characteristics
- Uses weighted profiling with dual sequence lengths (64/1024 tokens)
- Maintains memory quotas with configurable reserve ratios
- File: dual_gpu_optimizer/dualgpuopt/layer_balance.py

3. Real-time Telemetry System
- Tracks comprehensive GPU metrics:
  * Memory utilization and bandwidth
  * Power consumption patterns
  * Temperature and fan metrics
  * Clock speed optimization
- File: dual_gpu_optimizer/dualgpuopt/telemetry.py

4. GPU Command Generation
- Produces optimized commands for multiple ML frameworks:
  * llama.cpp with memory split configurations
  * vLLM with tensor parallelism settings
- Handles framework-specific parameters and environmental configurations
- File: dual_gpu_optimizer/dualgpuopt/commands/gpu_commands.py

5. Smart Batching System
- Implements length-aware inference scheduling
- Uses power-of-two and token ratio bucketing strategies
- Handles OOM conditions with automatic retry mechanisms
- File: dual_gpu_optimizer/dualgpuopt/batch/smart_batch.py

The system architecture emphasizes GPU resource optimization while maintaining system stability through:
- Safety-first overclocking controls
- Automatic failover mechanisms
- Real-time monitoring and adjustment
- Framework-specific optimization strategies

$END$
END SPECIFICATION