
START SPECIFICATION
<<<<<<< HEAD
---
<<<<<<< HEAD
<<<<<<< HEAD

description: Generate high-level overview documentation for GPU optimization and model inference systems, focusing on core business logic organizing GPU resource management, model execution, and telemetry collection
=======
description: Creates high-level documentation for dual GPU optimization systems focused on machine learning workload distribution and GPU resource management
>>>>>>> 0727adb (Update documentation for Dual GPU Optimizer, enhancing descriptions of core components and workflows related to machine learning workload distribution and GPU resource management. Refined glob patterns for improved file matching and organized content for better readability, ensuring clarity on system functionalities and integration points.)
globs: *.py,*.code-workspace
=======
description: Create a high-level overview documentation for projects focused on GPU optimization and management, particularly when dealing with multi-GPU setups for machine learning workloads and model execution
globs: *.py,*.json
>>>>>>> 3565cbc (Update documentation for DualGPUOptimizer to provide a comprehensive overview of GPU management, model optimization, execution management, and configuration handling. Enhanced descriptions for clarity and organized content for better readability. Adjusted glob patterns for improved file matching, ensuring accurate documentation coverage for multi-GPU setups in machine learning workloads.)
alwaysApply: false
---

# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.

The DualGPUOptimizer system implements specialized GPU optimization and model inference capabilities through several key business components:

<<<<<<< HEAD
<<<<<<< HEAD
## Core GPU Management (Importance: 95)

- GPU discovery and configuration management for dual GPU setups
- Intelligent memory split calculations between GPUs
- GPU telemetry collection and monitoring system
- Mock GPU mode for testing/development
- Advanced error handling for GPU-specific failures

Key files:

- `dualgpuopt/gpu_info.py`
- `dualgpuopt/telemetry.py`

## Model Optimization Engine (Importance: 90)

- Context size optimization based on GPU memory
- Layer balancing across multiple GPUs
- Dynamic tensor distribution
- Mixed precision policy management
- Smart batching with length-aware scheduling

Key files:

- `dualgpuopt/optimizer.py`
- `dualgpuopt/batch/smart_batch.py`

## Command System (Importance: 85)

- GPU-specific command generation for model execution
- Framework-specific optimizations for llama.cpp and vLLM
- Environment configuration generation
- Command history with undo capabilities

Key files:

- `dualgpuopt/commands/gpu_commands.py`

## Monitoring Dashboard (Importance: 80)

- Real-time GPU metrics visualization
- Historical utilization tracking
- Event-driven updates for GPU status
- Temperature and power monitoring

Key files:

- `dualgpuopt/gui/dashboard.py`
- `dualgpuopt/gui/event_dashboard.py`

## State Management (Importance: 75)

- Centralized configuration storage
- Event-driven state updates
- GPU settings persistence
- Theme and UI state management

Key files:

- `dualgpuopt/services/state_service.py`

The system uses an event-driven architecture to coordinate between components, with specialized services handling configuration, errors, and state management. The GUI provides multiple specialized views including an optimizer tab, launcher interface, and GPU monitoring dashboard.
=======
The Dual GPU Optimizer manages GPU resources and optimizes workload distribution across multiple GPUs for machine learning applications. The system consists of several key business components:
=======
The DualGPUOptimizer is a specialized application for managing and optimizing dual GPU setups, with core business functionality organized around three main areas:
>>>>>>> 3565cbc (Update documentation for DualGPUOptimizer to provide a comprehensive overview of GPU management, model optimization, execution management, and configuration handling. Enhanced descriptions for clarity and organized content for better readability. Adjusted glob patterns for improved file matching, ensuring accurate documentation coverage for multi-GPU setups in machine learning workloads.)

## GPU Management and Monitoring (Importance: 95)
- Probes and validates GPU configurations through NVML integration
- Collects comprehensive GPU metrics including memory, utilization, PCIe throughput, power usage
- Implements continuous telemetry streaming for real-time GPU performance monitoring
- Provides mock GPU functionality for testing and development

Key files:
- `dualgpuopt/gpu_info.py`
- `dualgpuopt/telemetry.py`

## Model Optimization Engine (Importance: 90)
- Generates optimized GPU split configurations based on available GPU memory
- Creates environment configurations for CUDA and NCCL optimizations
- Produces framework-specific command strings for llama.cpp and vLLM
- Manages model presets and configurations for common ML models

Key files:
- `dualgpuopt/optimizer.py`
- `dualgpuopt/gui/optimizer_tab.py`

<<<<<<< HEAD
### Application Control Flow (Importance: 75)
- Dual-mode operation (CLI and GUI) for flexibility
- GPU configuration validation and requirement checking
- Environment variable management for framework compatibility
- Located in: `dual_gpu_optimizer/dualgpuopt/__main__.py`
>>>>>>> 0727adb (Update documentation for Dual GPU Optimizer, enhancing descriptions of core components and workflows related to machine learning workload distribution and GPU resource management. Refined glob patterns for improved file matching and organized content for better readability, ensuring clarity on system functionalities and integration points.)
=======
## Execution Management (Importance: 85)
- Controls model execution across multiple GPUs
- Manages process lifecycle and logging for running models
- Provides real-time monitoring through an interactive dashboard
- Implements idle detection and resource optimization alerts

Key files:
- `dualgpuopt/gui/launcher.py`
- `dualgpuopt/gui/dashboard.py`
- `dualgpuopt/tray.py`

## Configuration and Theme Management (Importance: 75)
- Handles GPU-specific overclocking settings and persistence
- Manages application themes with support for multiple color schemes
- Maintains user preferences and GPU configurations across sessions

Key files:
- `dualgpuopt/gui/settings.py`
- `dualgpuopt/gui/theme.py`

The application integrates these components through a GUI interface that provides real-time monitoring, optimization controls, and model execution management, specifically designed for machine learning workloads on multi-GPU systems.
>>>>>>> 3565cbc (Update documentation for DualGPUOptimizer to provide a comprehensive overview of GPU management, model optimization, execution management, and configuration handling. Enhanced descriptions for clarity and organized content for better readability. Adjusted glob patterns for improved file matching, ensuring accurate documentation coverage for multi-GPU setups in machine learning workloads.)

$END$
END SPECIFICATION

START SPECIFICATION
---

description: Create high-level technical documentation focused on GPU optimization, monitoring, and control logic, particularly for dual GPU systems with complex business workflows
globs: *.py
alwaysApply: false
---

# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.

## Core Business Logic

### GPU Optimization Engine

Key system for optimizing dual GPU performance through:

- Adaptive layer redistribution between GPUs based on performance profiles
- Context size calculation considering GPU memory and model parameters
- Dynamic mixed precision policies for optimized GPU memory usage
- Telemetry collection pipeline for real-time GPU metrics

### GPU Control and Management

Central system components:

- Overclocking control with safety checks and configuration persistence
- Fan speed management with automatic and manual control modes
- Power limit adjustments with validation
- Temperature monitoring and throttling protection

### Event-Driven Monitoring

Real-time monitoring architecture:

- GPU metrics collection including utilization, memory, temperature, power
- Historical data tracking for performance analysis
- Priority-based event dispatch system
- Idle detection and notification system

### Model Execution Optimization

Specialized logic for model deployment:

- Smart batch processing with length-aware scheduling
- GPU memory split calculations for optimal model distribution
- Framework-specific command generation (llama.cpp, vLLM)
- Environment configuration generation

### Dashboard System

Real-time visualization components:

- Multi-GPU metrics display with color-coded indicators
- Performance history graphs with trend analysis
- PCIe bandwidth monitoring and formatting
- Temperature and power threshold management

Critical Paths:

- `dual_gpu_optimizer/dualgpuopt/optimizer.py`
- `dual_gpu_optimizer/dualgpuopt/layer_balance.py`
- `dual_gpu_optimizer/dualgpuopt/batch/smart_batch.py`
- `dual_gpu_optimizer/dualgpuopt/telemetry.py`

$END$
END SPECIFICATION

START SPECIFICATION:
---
description: Create high-level documentation for projects focused on GPU optimization and management, particularly for dual-GPU setups running large language models. Apply when documenting systems that handle GPU resource allocation, model deployment, and hardware monitoring.
globs: dual_gpu_optimizer/**,integrated_app/**,dualgpuopt/**
alwaysApply: false
---


# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


The DualGPUOptimizer implements specialized GPU resource management and optimization for large language models across dual GPU configurations. The system consists of three core business domains:

1. GPU Resource Management
- Context size calculation with model-specific parameters
- Memory split optimization between GPUs
- Layer balancing across devices
- Tensor parallelism configuration
- Power and thermal monitoring

Key files:
- dualgpuopt/ctx_size.py
- dualgpuopt/layer_balance.py
- dualgpuopt/optimizer.py

2. Model Deployment Optimization
- Framework-specific command generation
- Batch size optimization
- Idle detection and resource reallocation
- Mixed precision policies
- Memory safety margins

Key files:
- dualgpuopt/batch/smart_batch.py
- dualgpuopt/mpolicy.py
- dualgpuopt/commands/gpu_commands.py

3. Telemetry and Monitoring
- Real-time GPU metrics collection
- Performance visualization
- Temperature threshold monitoring
- Power usage tracking
- Memory utilization analysis

Key files:
- dualgpuopt/telemetry.py
- dualgpuopt/gui/dashboard.py
- dualgpuopt/metrics.py

The system implements specialized handling for:
- Model-specific memory requirements (Mixtral, Llama 2, Mistral)
- Framework-specific optimizations (llama.cpp, vLLM)  
- GPU safety constraints and thermal limits
- Resource allocation strategies
- Fault tolerance and recovery

Business value centers on optimizing large language model deployment across heterogeneous GPU configurations while maintaining system stability and performance.

$END$
END SPECIFICATION
