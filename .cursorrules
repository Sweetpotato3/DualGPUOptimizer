
START SPECIFICATION
---

description: Generate high-level overview documentation for GPU optimization and model inference systems, focusing on core business logic organizing GPU resource management, model execution, and telemetry collection
globs: *.py,*.code-workspace
alwaysApply: false
---

# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.

The DualGPUOptimizer system implements specialized GPU optimization and model inference capabilities through several key business components:

## Core GPU Management (Importance: 95)

- GPU discovery and configuration management for dual GPU setups
- Intelligent memory split calculations between GPUs
- GPU telemetry collection and monitoring system
- Mock GPU mode for testing/development
- Advanced error handling for GPU-specific failures

Key files:

- `dualgpuopt/gpu_info.py`
- `dualgpuopt/telemetry.py`

## Model Optimization Engine (Importance: 90)

- Context size optimization based on GPU memory
- Layer balancing across multiple GPUs
- Dynamic tensor distribution
- Mixed precision policy management
- Smart batching with length-aware scheduling

Key files:

- `dualgpuopt/optimizer.py`
- `dualgpuopt/batch/smart_batch.py`

## Command System (Importance: 85)

- GPU-specific command generation for model execution
- Framework-specific optimizations for llama.cpp and vLLM
- Environment configuration generation
- Command history with undo capabilities

Key files:

- `dualgpuopt/commands/gpu_commands.py`

## Monitoring Dashboard (Importance: 80)

- Real-time GPU metrics visualization
- Historical utilization tracking
- Event-driven updates for GPU status
- Temperature and power monitoring

Key files:

- `dualgpuopt/gui/dashboard.py`
- `dualgpuopt/gui/event_dashboard.py`

## State Management (Importance: 75)

- Centralized configuration storage
- Event-driven state updates
- GPU settings persistence
- Theme and UI state management

Key files:

- `dualgpuopt/services/state_service.py`

The system uses an event-driven architecture to coordinate between components, with specialized services handling configuration, errors, and state management. The GUI provides multiple specialized views including an optimizer tab, launcher interface, and GPU monitoring dashboard.

$END$
END SPECIFICATION

START SPECIFICATION
---

description: Create high-level technical documentation focused on GPU optimization, monitoring, and control logic, particularly for dual GPU systems with complex business workflows
globs: *.py
alwaysApply: false
---

# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.

## Core Business Logic

### GPU Optimization Engine

Key system for optimizing dual GPU performance through:

- Adaptive layer redistribution between GPUs based on performance profiles
- Context size calculation considering GPU memory and model parameters
- Dynamic mixed precision policies for optimized GPU memory usage
- Telemetry collection pipeline for real-time GPU metrics

### GPU Control and Management

Central system components:

- Overclocking control with safety checks and configuration persistence
- Fan speed management with automatic and manual control modes
- Power limit adjustments with validation
- Temperature monitoring and throttling protection

### Event-Driven Monitoring

Real-time monitoring architecture:

- GPU metrics collection including utilization, memory, temperature, power
- Historical data tracking for performance analysis
- Priority-based event dispatch system
- Idle detection and notification system

### Model Execution Optimization

Specialized logic for model deployment:

- Smart batch processing with length-aware scheduling
- GPU memory split calculations for optimal model distribution
- Framework-specific command generation (llama.cpp, vLLM)
- Environment configuration generation

### Dashboard System

Real-time visualization components:

- Multi-GPU metrics display with color-coded indicators
- Performance history graphs with trend analysis
- PCIe bandwidth monitoring and formatting
- Temperature and power threshold management

Critical Paths:

- `dual_gpu_optimizer/dualgpuopt/optimizer.py`
- `dual_gpu_optimizer/dualgpuopt/layer_balance.py`
- `dual_gpu_optimizer/dualgpuopt/batch/smart_batch.py`
- `dual_gpu_optimizer/dualgpuopt/telemetry.py`

$END$
END SPECIFICATION

START SPECIFICATION:
---
description: Generate high-level overview documentation focused on core business logic and domain-specific implementations in GPU optimization and monitoring systems
globs: *.py,*.code-workspace
alwaysApply: false
---


# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


The DualGPUOptimizer implements specialized logic for optimizing dual GPU setups in machine learning environments through several key components:

### Core GPU Optimization Logic
- GPU split calculation for workload distribution across multiple GPUs
- Dynamic tensor fraction calculations based on available GPU memory 
- Environment configuration generation for optimal GPU utilization
- Custom command generation for model runners (llama.cpp, vLLM)

### Real-time GPU Telemetry 
- Continuous collection of GPU metrics (utilization, memory, temperature, power)
- Middleware pipeline for telemetry processing and event distribution
- Priority-based event dispatching system for metrics updates
- Historical GPU usage tracking and visualization

### Optimization Dashboard
- Dynamic GPU metrics visualization with real-time updates
- Interactive controls for overclocking and fan speed management
- Model preset management for quick configuration
- Command generation interface for model deployment

### State Management and Configuration
- Centralized state service with event notifications
- Configuration persistence with automatic defaults
- Error handling specialized for GPU operations
- Mock GPU mode for testing and demonstration

Key Implementation Files:
- `dualgpuopt/optimizer.py`: Core GPU optimization algorithms
- `dualgpuopt/telemetry.py`: GPU metrics collection and processing
- `dualgpuopt/services/event_bus.py`: Event distribution system
- `dualgpuopt/gui/dashboard.py`: Real-time metrics visualization
- `dualgpuopt/commands/gpu_commands.py`: GPU control operations

The system uses an event-driven architecture where GPU telemetry data flows through a processing pipeline, triggering UI updates and optimization decisions. The optimization logic focuses on workload distribution and resource utilization across multiple GPUs, while providing real-time monitoring and control capabilities.

$END$
END SPECIFICATION