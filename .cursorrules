
START SPECIFICATION:
---
description: Use this overview documentation when analyzing dual GPU optimization systems focused on LLM workload distribution and performance monitoring, particularly for projects handling real-time GPU metrics and tensor operations across multiple devices.
globs: *.py,*.code-workspace
alwaysApply: false
---


# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


The Dual GPU Optimizer system implements specialized logic for managing and optimizing GPU resources for large language model deployments. The core business functionality is organized into three main domains:

1. GPU Resource Management & Optimization (Importance: 95)
- Specialized tensor distribution algorithms for dual GPU configurations
- Dynamic memory split calculations based on GPU capabilities
- Framework-specific optimization parameters for llama.cpp and vLLM
- Automatic hardware capability detection and profiling
- Real-time utilization monitoring with 60-sample rolling windows

2. Performance Monitoring & Telemetry (Importance: 85)
- Custom event hierarchy for GPU-specific monitoring
- Real-time metrics collection including utilization, memory usage, temperature
- PCIe bandwidth monitoring with automatic unit scaling
- Temperature and power consumption correlation tracking
- Idle detection system with configurable thresholds

3. Overclocking Management (Importance: 80)
- GPU-specific overclocking profiles with safety bounds
- Core/Memory clock offset management
- Power limit and fan speed control
- Profile persistence and rollback capabilities
- Hardware safety limit enforcement

Key Implementation Files:
- dualgpuopt/optimizer.py: Core GPU optimization logic
- dualgpuopt/gpu_info.py: Hardware profiling and metrics
- dualgpuopt/telemetry.py: Real-time monitoring system
- dualgpuopt/services/event_bus.py: GPU event management

The system focuses on optimizing dual-GPU setups for AI model deployment through:
- Real-time performance monitoring
- Dynamic tensor distribution
- Hardware-specific configuration generation
- Fault-tolerant operation handling
- Framework-specific launch strategies

$END$
END SPECIFICATION