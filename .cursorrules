START SPECIFICATION
---
description: Create a high-level overview documentation for projects focused on GPU optimization and management, particularly when dealing with multi-GPU setups for machine learning workloads and model execution
globs: *.py,*.json
alwaysApply: false
---

# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.

The DualGPUOptimizer is a specialized application for managing and optimizing dual GPU setups, with core business functionality organized around three main areas:

## GPU Management and Monitoring (Importance: 95)
- Probes and validates GPU configurations through NVML integration
- Collects comprehensive GPU metrics including memory, utilization, PCIe throughput, power usage
- Implements continuous telemetry streaming for real-time GPU performance monitoring
- Provides mock GPU functionality for testing and development

Key files:
- `dualgpuopt/gpu_info.py`
- `dualgpuopt/telemetry.py`

## Model Optimization Engine (Importance: 90)
- Generates optimized GPU split configurations based on available GPU memory
- Creates environment configurations for CUDA and NCCL optimizations
- Produces framework-specific command strings for llama.cpp and vLLM
- Manages model presets and configurations for common ML models

Key files:
- `dualgpuopt/optimizer.py`
- `dualgpuopt/gui/optimizer_tab.py`

## Execution Management (Importance: 85)
- Controls model execution across multiple GPUs
- Manages process lifecycle and logging for running models
- Provides real-time monitoring through an interactive dashboard
- Implements idle detection and resource optimization alerts

Key files:
- `dualgpuopt/gui/launcher.py`
- `dualgpuopt/gui/dashboard.py`
- `dualgpuopt/tray.py`

## Configuration and Theme Management (Importance: 75)
- Handles GPU-specific overclocking settings and persistence
- Manages application themes with support for multiple color schemes
- Maintains user preferences and GPU configurations across sessions

Key files:
- `dualgpuopt/gui/settings.py`
- `dualgpuopt/gui/theme.py`

The application integrates these components through a GUI interface that provides real-time monitoring, optimization controls, and model execution management, specifically designed for machine learning workloads on multi-GPU systems.

$END$
END SPECIFICATION

START SPECIFICATION
---
description: Create high-level technical documentation focused on GPU optimization, monitoring, and control logic, particularly for dual GPU systems with complex business workflows
globs: *.py
alwaysApply: false
---

# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.

## Core Business Logic

### GPU Optimization Engine

Key system for optimizing dual GPU performance through:

- Adaptive layer redistribution between GPUs based on performance profiles
- Context size calculation considering GPU memory and model parameters
- Dynamic mixed precision policies for optimized GPU memory usage
- Telemetry collection pipeline for real-time GPU metrics

### GPU Control and Management

Central system components:

- Overclocking control with safety checks and configuration persistence
- Fan speed management with automatic and manual control modes
- Power limit adjustments with validation
- Temperature monitoring and throttling protection

### Event-Driven Monitoring

Real-time monitoring architecture:

- GPU metrics collection including utilization, memory, temperature, power
- Historical data tracking for performance analysis
- Priority-based event dispatch system
- Idle detection and notification system

### Model Execution Optimization

Specialized logic for model deployment:

- Smart batch processing with length-aware scheduling
- GPU memory split calculations for optimal model distribution
- Framework-specific command generation (llama.cpp, vLLM)
- Environment configuration generation

### Dashboard System

Real-time visualization components:

- Multi-GPU metrics display with color-coded indicators
- Performance history graphs with trend analysis
- PCIe bandwidth monitoring and formatting
- Temperature and power threshold management

Critical Paths:

- `dualgpuopt/optimizer.py`
- `dualgpuopt/layer_balance.py`
- `dualgpuopt/batch/smart_batch.py`
- `dualgpuopt/telemetry.py`

$END$
END SPECIFICATION

START SPECIFICATION:
---
description: Generate high-level overview documentation for projects focused on GPU optimization and machine learning model deployment, particularly those dealing with multi-GPU resource management, memory optimization, and model inference.
globs: *.py,*/gpu/*.py,*/ml/*.py,*/optimize/*.py
alwaysApply: false
---


# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


The DualGPUOptimizer system implements specialized logic for optimizing large language model deployment across multiple GPUs.

Core Business Components:

1. GPU Resource Management (dualgpuopt/optimizer.py)
- Dynamic GPU memory allocation with tensor splitting 
- Intelligent layer distribution across GPUs
- Framework-specific command generation for llama.cpp and vLLM
- Memory pressure monitoring and automatic rebalancing

2. Model Memory Management (dualgpuopt/memory_monitor.py)
- Pre-configured profiles for common LLMs (LLaMA2, Mistral, Mixtral)
- Dynamic batch size calculation based on model architecture
- OOM prevention through multi-stage recovery
- Memory growth projection and usage tracking

3. Layer Balancing System (dualgpuopt/layer_balance.py)
- Performance-weighted layer distribution algorithm
- Long sequence optimization (80% weight for 1024 tokens)
- Short sequence handling (20% weight for 64 tokens) 
- Small block merging for contiguous execution

4. Smart Batching (dualgpuopt/batch/smart_batch.py)
- Length-aware sequence grouping
- Dynamic batch size adjustment based on memory constraints
- Back-pressure mechanism for OOM prevention
- Token count limits and safety margins

5. GPU Telemetry (dualgpuopt/telemetry.py)
- Real-time metrics collection including memory, temperature, power
- Event-driven metrics distribution through middleware
- Graceful degradation with mock data generation
- Continuous monitoring with configurable intervals

The core business value lies in intelligent distribution of model layers and memory management across multiple GPUs, with specialized optimizations for:
- Large language model architectures
- Mixed precision operations 
- Memory bandwidth utilization
- Cross-GPU latency management

Key integration points:
- Framework-specific command generation (llama.cpp, vLLM)
- Model architecture detection from filenames
- GPU performance profiling and metrics collection
- OOM prevention and recovery orchestration

$END$
END SPECIFICATION
