
START SPECIFICATION
<<<<<<< HEAD
---
<<<<<<< HEAD
<<<<<<< HEAD

description: Generate high-level overview documentation for GPU optimization and model inference systems, focusing on core business logic organizing GPU resource management, model execution, and telemetry collection
=======
description: Creates high-level documentation for dual GPU optimization systems focused on machine learning workload distribution and GPU resource management
>>>>>>> 0727adb (Update documentation for Dual GPU Optimizer, enhancing descriptions of core components and workflows related to machine learning workload distribution and GPU resource management. Refined glob patterns for improved file matching and organized content for better readability, ensuring clarity on system functionalities and integration points.)
globs: *.py,*.code-workspace
=======
description: Create a high-level overview documentation for projects focused on GPU optimization and management, particularly when dealing with multi-GPU setups for machine learning workloads and model execution
globs: *.py,*.json
>>>>>>> 3565cbc (Update documentation for DualGPUOptimizer to provide a comprehensive overview of GPU management, model optimization, execution management, and configuration handling. Enhanced descriptions for clarity and organized content for better readability. Adjusted glob patterns for improved file matching, ensuring accurate documentation coverage for multi-GPU setups in machine learning workloads.)
alwaysApply: false
---

# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.

The DualGPUOptimizer system implements specialized GPU optimization and model inference capabilities through several key business components:

<<<<<<< HEAD
<<<<<<< HEAD
## Core GPU Management (Importance: 95)

- GPU discovery and configuration management for dual GPU setups
- Intelligent memory split calculations between GPUs
- GPU telemetry collection and monitoring system
- Mock GPU mode for testing/development
- Advanced error handling for GPU-specific failures

Key files:

- `dualgpuopt/gpu_info.py`
- `dualgpuopt/telemetry.py`

## Model Optimization Engine (Importance: 90)

- Context size optimization based on GPU memory
- Layer balancing across multiple GPUs
- Dynamic tensor distribution
- Mixed precision policy management
- Smart batching with length-aware scheduling

Key files:

- `dualgpuopt/optimizer.py`
- `dualgpuopt/batch/smart_batch.py`

## Command System (Importance: 85)

- GPU-specific command generation for model execution
- Framework-specific optimizations for llama.cpp and vLLM
- Environment configuration generation
- Command history with undo capabilities

Key files:

- `dualgpuopt/commands/gpu_commands.py`

## Monitoring Dashboard (Importance: 80)

- Real-time GPU metrics visualization
- Historical utilization tracking
- Event-driven updates for GPU status
- Temperature and power monitoring

Key files:

- `dualgpuopt/gui/dashboard.py`
- `dualgpuopt/gui/event_dashboard.py`

## State Management (Importance: 75)

- Centralized configuration storage
- Event-driven state updates
- GPU settings persistence
- Theme and UI state management

Key files:

- `dualgpuopt/services/state_service.py`

The system uses an event-driven architecture to coordinate between components, with specialized services handling configuration, errors, and state management. The GUI provides multiple specialized views including an optimizer tab, launcher interface, and GPU monitoring dashboard.
=======
The Dual GPU Optimizer manages GPU resources and optimizes workload distribution across multiple GPUs for machine learning applications. The system consists of several key business components:
=======
The DualGPUOptimizer is a specialized application for managing and optimizing dual GPU setups, with core business functionality organized around three main areas:
>>>>>>> 3565cbc (Update documentation for DualGPUOptimizer to provide a comprehensive overview of GPU management, model optimization, execution management, and configuration handling. Enhanced descriptions for clarity and organized content for better readability. Adjusted glob patterns for improved file matching, ensuring accurate documentation coverage for multi-GPU setups in machine learning workloads.)

## GPU Management and Monitoring (Importance: 95)
- Probes and validates GPU configurations through NVML integration
- Collects comprehensive GPU metrics including memory, utilization, PCIe throughput, power usage
- Implements continuous telemetry streaming for real-time GPU performance monitoring
- Provides mock GPU functionality for testing and development

Key files:
- `dualgpuopt/gpu_info.py`
- `dualgpuopt/telemetry.py`

## Model Optimization Engine (Importance: 90)
- Generates optimized GPU split configurations based on available GPU memory
- Creates environment configurations for CUDA and NCCL optimizations
- Produces framework-specific command strings for llama.cpp and vLLM
- Manages model presets and configurations for common ML models

Key files:
- `dualgpuopt/optimizer.py`
- `dualgpuopt/gui/optimizer_tab.py`

<<<<<<< HEAD
### Application Control Flow (Importance: 75)
- Dual-mode operation (CLI and GUI) for flexibility
- GPU configuration validation and requirement checking
- Environment variable management for framework compatibility
- Located in: `dual_gpu_optimizer/dualgpuopt/__main__.py`
>>>>>>> 0727adb (Update documentation for Dual GPU Optimizer, enhancing descriptions of core components and workflows related to machine learning workload distribution and GPU resource management. Refined glob patterns for improved file matching and organized content for better readability, ensuring clarity on system functionalities and integration points.)
=======
## Execution Management (Importance: 85)
- Controls model execution across multiple GPUs
- Manages process lifecycle and logging for running models
- Provides real-time monitoring through an interactive dashboard
- Implements idle detection and resource optimization alerts

Key files:
- `dualgpuopt/gui/launcher.py`
- `dualgpuopt/gui/dashboard.py`
- `dualgpuopt/tray.py`

## Configuration and Theme Management (Importance: 75)
- Handles GPU-specific overclocking settings and persistence
- Manages application themes with support for multiple color schemes
- Maintains user preferences and GPU configurations across sessions

Key files:
- `dualgpuopt/gui/settings.py`
- `dualgpuopt/gui/theme.py`

The application integrates these components through a GUI interface that provides real-time monitoring, optimization controls, and model execution management, specifically designed for machine learning workloads on multi-GPU systems.
>>>>>>> 3565cbc (Update documentation for DualGPUOptimizer to provide a comprehensive overview of GPU management, model optimization, execution management, and configuration handling. Enhanced descriptions for clarity and organized content for better readability. Adjusted glob patterns for improved file matching, ensuring accurate documentation coverage for multi-GPU setups in machine learning workloads.)

$END$
END SPECIFICATION

START SPECIFICATION
---

description: Create high-level technical documentation focused on GPU optimization, monitoring, and control logic, particularly for dual GPU systems with complex business workflows
globs: *.py
alwaysApply: false
---

# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.

## Core Business Logic

### GPU Optimization Engine

Key system for optimizing dual GPU performance through:

- Adaptive layer redistribution between GPUs based on performance profiles
- Context size calculation considering GPU memory and model parameters
- Dynamic mixed precision policies for optimized GPU memory usage
- Telemetry collection pipeline for real-time GPU metrics

### GPU Control and Management

Central system components:

- Overclocking control with safety checks and configuration persistence
- Fan speed management with automatic and manual control modes
- Power limit adjustments with validation
- Temperature monitoring and throttling protection

### Event-Driven Monitoring

Real-time monitoring architecture:

- GPU metrics collection including utilization, memory, temperature, power
- Historical data tracking for performance analysis
- Priority-based event dispatch system
- Idle detection and notification system

### Model Execution Optimization

Specialized logic for model deployment:

- Smart batch processing with length-aware scheduling
- GPU memory split calculations for optimal model distribution
- Framework-specific command generation (llama.cpp, vLLM)
- Environment configuration generation

### Dashboard System

Real-time visualization components:

- Multi-GPU metrics display with color-coded indicators
- Performance history graphs with trend analysis
- PCIe bandwidth monitoring and formatting
- Temperature and power threshold management

Critical Paths:

- `dual_gpu_optimizer/dualgpuopt/optimizer.py`
- `dual_gpu_optimizer/dualgpuopt/layer_balance.py`
- `dual_gpu_optimizer/dualgpuopt/batch/smart_batch.py`
- `dual_gpu_optimizer/dualgpuopt/telemetry.py`

$END$
END SPECIFICATION

START SPECIFICATION:
---
description: Rules for documenting dual GPU optimization systems for ML workloads, covering GPU resource management, monitoring, and parallel execution strategies
globs: *.py,*.code-workspace
alwaysApply: false
---


# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


DualGPUOptimizer delivers intelligent GPU resource management and optimization for machine learning workloads across multiple GPUs.

Core Business Components:

1. GPU Resource Management
- Memory splitting algorithms distribute model layers across GPUs
- Adaptive tensor parallelism fractions based on GPU capabilities
- Dynamic memory quotas with 90% allocation safety threshold
- MoE-aware context sizing with 1.05x gating cache factor

2. Workload Optimization
- Length-aware batch scheduling for inference optimization 
- Power-of-two bucketing strategy similar to llama.cpp
- Token ratio bucketing maintains configurable size ratios
- Back-pressure system prevents GPU memory overflow

3. Hardware Monitoring
- Real-time GPU metrics collection:
  - Utilization percentages
  - Memory allocation tracking 
  - Temperature monitoring with 80°C warning threshold
  - Power draw monitoring against 400W maximum
- Rolling 60-sample performance history

4. Framework Integration
- Framework-specific command generation:
  - llama.cpp: GPU split parameters
  - vLLM: Tensor parallelism configs
- Mixed precision policies maintain FP32 for critical operations

Critical Paths:
- dualgpuopt/optimizer.py: Core optimization logic
- dualgpuopt/layer_balance.py: Layer distribution system
- dualgpuopt/telemetry.py: GPU metrics collection
- dualgpuopt/mpolicy.py: Mixed precision management

The system focuses on maximizing GPU resource utilization while maintaining stability through careful memory management and workload distribution across multiple GPUs.

$END$
END SPECIFICATION
