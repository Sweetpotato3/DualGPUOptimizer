---
description: Create a high-level overview documentation for projects focused on GPU optimization and management, particularly when dealing with multi-GPU setups for machine learning workloads and model execution
globs: *.py,*.json
alwaysApply: false
---

# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.

The DualGPUOptimizer is a specialized application for managing and optimizing dual GPU setups, with core business functionality organized around three main areas:

## GPU Management and Monitoring (Importance: 95)
- Probes and validates GPU configurations through NVML integration
- Collects comprehensive GPU metrics including memory, utilization, PCIe throughput, power usage
- Implements continuous telemetry streaming for real-time GPU performance monitoring
- Provides mock GPU functionality for testing and development

Key files:
- `dualgpuopt/gpu_info.py`
- `dualgpuopt/telemetry.py`

## Model Optimization Engine (Importance: 90)
- Generates optimized GPU split configurations based on available GPU memory
- Creates environment configurations for CUDA and NCCL optimizations
- Produces framework-specific command strings for llama.cpp and vLLM
- Manages model presets and configurations for common ML models

Key files:
- `dualgpuopt/optimizer.py`
- `dualgpuopt/gui/optimizer_tab.py`

## Execution Management (Importance: 85)
- Controls model execution across multiple GPUs
- Manages process lifecycle and logging for running models
- Provides real-time monitoring through an interactive dashboard
- Implements idle detection and resource optimization alerts

Key files:
- `dualgpuopt/gui/launcher.py`
- `dualgpuopt/gui/dashboard.py`
- `dualgpuopt/tray.py`

## Configuration and Theme Management (Importance: 75)
- Handles GPU-specific overclocking settings and persistence
- Manages application themes with support for multiple color schemes
- Maintains user preferences and GPU configurations across sessions

Key files:
- `dualgpuopt/gui/settings.py`
- `dualgpuopt/gui/theme.py`

The application integrates these components through a GUI interface that provides real-time monitoring, optimization controls, and model execution management, specifically designed for machine learning workloads on multi-GPU systems.

$END$
END SPECIFICATION

START SPECIFICATION
---
description: Create high-level technical documentation focused on GPU optimization, monitoring, and control logic, particularly for dual GPU systems with complex business workflows
globs: *.py
alwaysApply: false
---

# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.

## Core Business Logic

### GPU Optimization Engine

Key system for optimizing dual GPU performance through:

- Adaptive layer redistribution between GPUs based on performance profiles
- Context size calculation considering GPU memory and model parameters
- Dynamic mixed precision policies for optimized GPU memory usage
- Telemetry collection pipeline for real-time GPU metrics

### GPU Control and Management

Central system components:

- Overclocking control with safety checks and configuration persistence
- Fan speed management with automatic and manual control modes
- Power limit adjustments with validation
- Temperature monitoring and throttling protection

### Event-Driven Monitoring

Real-time monitoring architecture:

- GPU metrics collection including utilization, memory, temperature, power
- Historical data tracking for performance analysis
- Priority-based event dispatch system
- Idle detection and notification system

### Model Execution Optimization

Specialized logic for model deployment:

- Smart batch processing with length-aware scheduling
- GPU memory split calculations for optimal model distribution
- Framework-specific command generation (llama.cpp, vLLM)
- Environment configuration generation

### Dashboard System

Real-time visualization components:

- Multi-GPU metrics display with color-coded indicators
- Performance history graphs with trend analysis
- PCIe bandwidth monitoring and formatting
- Temperature and power threshold management

Critical Paths:

- `dualgpuopt/optimizer.py`
- `dualgpuopt/layer_balance.py`
- `dualgpuopt/batch/smart_batch.py`
- `dualgpuopt/telemetry.py`

$END$
END SPECIFICATION

START SPECIFICATION:
---
description: Generate high-level technical documentation overviews for GPU optimization and monitoring systems, focusing on dual-GPU configurations and machine learning model deployment patterns.
globs: *.py,*/dualgpuopt/**/*.py
alwaysApply: false
---


# main-overview

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


DualGPUOptimizer provides a system for optimizing large language model inference across dual GPU configurations with memory analysis and monitoring capabilities.

Core Business Architecture:

1. GPU Memory Profiling (dualgpuopt/memory/profiler.py)
- Real-time memory tracking and analysis for dual-GPU setups
- Session-based profiling with inference tracking
- Memory leak detection using linear regression
- Pattern analysis with sliding window metrics

2. Optimization Engine (dualgpuopt/optimizer.py)
- GPU memory split optimization
- Tensor parallel size calculation
- Dynamic context length adjustment
- Framework-specific command generation for deployment

3. Layer Balancing System (dualgpuopt/layer_balance.py)
- Adaptive layer distribution across GPUs
- Weighted sequence profiling (64/1024 tokens)
- Memory quota-based assignment
- Block optimization for contiguous layers

4. Memory Predictor (dualgpuopt/memory/predictor.py)
- Model-specific memory profiling
- Growth projection algorithms
- Batch size optimization
- Memory safety mechanisms

5. GPU Telemetry (dualgpuopt/telemetry.py)
- Real-time metric collection
- Multi-GPU synchronization
- Fault tolerance with mock data generation
- Middleware pipeline architecture

Key Integration Points:

1. Framework Support
- llama.cpp optimization paths
- vLLM configuration management
- Tensor parallel deployment
- Mixed precision execution

2. Model Architecture Support
- LLaMA variants (7B, 13B, 70B)
- Mistral architecture
- Mixtral with MoE handling
- Context length optimization

The system prioritizes memory safety while maximizing GPU utilization through intelligent workload distribution and real-time monitoring, with particular emphasis on large language model deployment optimization.

$END$
END SPECIFICATION
